{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = '5'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "checkpoint_path = './pth'\n",
    "\n",
    "torch.set_num_threads(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.precision', 20)\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "class CFG:\n",
    "    batch_size=64\n",
    "    n_time = 3\n",
    "    total_n_bssid = 60\n",
    "    n_bssid = 40\n",
    "    n_tar = 1\n",
    "    ibeacon_seq_len = 20\n",
    "    n_sensor = 6\n",
    "    n_sensor_feature = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReadData:\n",
    "    acce: np.ndarray\n",
    "    acce_uncali: np.ndarray\n",
    "    gyro: np.ndarray\n",
    "    gyro_uncali: np.ndarray\n",
    "    magn: np.ndarray\n",
    "    magn_uncali: np.ndarray\n",
    "    ahrs: np.ndarray\n",
    "    wifi: np.ndarray\n",
    "    ibeacon: np.ndarray\n",
    "    waypoint: np.ndarray\n",
    "\n",
    "\n",
    "def read_data_file(data_filename):\n",
    "    acce = []\n",
    "    acce_uncali = []\n",
    "    gyro = []\n",
    "    gyro_uncali = []\n",
    "    magn = []\n",
    "    magn_uncali = []\n",
    "    ahrs = []\n",
    "    wifi = []\n",
    "    ibeacon = []\n",
    "    waypoint = []\n",
    "\n",
    "    with open(data_filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line_data in lines:\n",
    "        line_data = line_data.strip()\n",
    "        if not line_data or line_data[0] == '#':\n",
    "            continue\n",
    "\n",
    "        line_data = line_data.split('\\t')\n",
    "\n",
    "        if line_data[1] == 'TYPE_WAYPOINT':\n",
    "            waypoint.append([int(line_data[0]), float(line_data[2]), float(line_data[3])])\n",
    "            continue\n",
    "       \n",
    "        if line_data[1] == 'TYPE_ACCELEROMETER':\n",
    "            acce.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "        \n",
    "        if line_data[1] == 'TYPE_ACCELEROMETER_UNCALIBRATED':\n",
    "            acce_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "        \n",
    "        if line_data[1] == 'TYPE_GYROSCOPE':\n",
    "            gyro.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_GYROSCOPE_UNCALIBRATED':\n",
    "            gyro_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "        \n",
    "        if line_data[1] == 'TYPE_MAGNETIC_FIELD':\n",
    "            magn.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_MAGNETIC_FIELD_UNCALIBRATED':\n",
    "            magn_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_ROTATION_VECTOR':\n",
    "            ahrs.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_WIFI':\n",
    "            sys_ts = line_data[0]\n",
    "            ssid = line_data[2]\n",
    "            bssid = line_data[3]\n",
    "            rssi = line_data[4]\n",
    "            lastseen_ts = line_data[6]\n",
    "            wifi_data = [sys_ts, ssid, bssid, rssi, lastseen_ts]\n",
    "            wifi.append(wifi_data)\n",
    "            continue\n",
    "\n",
    "        if line_data[1] == 'TYPE_BEACON':\n",
    "            ts = line_data[0]\n",
    "            uuid = line_data[2]\n",
    "            major = line_data[3]\n",
    "            minor = line_data[4]\n",
    "            rssi = line_data[6]\n",
    "            ibeacon_data = [ts, '_'.join([uuid, major, minor]), rssi]\n",
    "            ibeacon.append(ibeacon_data)\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    acce = np.array(acce)\n",
    "    acce_uncali = np.array(acce_uncali)\n",
    "    gyro = np.array(gyro)\n",
    "    gyro_uncali = np.array(gyro_uncali)\n",
    "    magn = np.array(magn)\n",
    "    magn_uncali = np.array(magn_uncali)\n",
    "    ahrs = np.array(ahrs)\n",
    "    wifi = np.array(wifi)\n",
    "    ibeacon = np.array(ibeacon)\n",
    "    waypoint = np.array(waypoint)\n",
    "    \n",
    "    return ReadData(acce, acce_uncali, gyro, gyro_uncali, magn, magn_uncali, ahrs, wifi, ibeacon, waypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acce shape: (974, 4)\n",
      "acce_uncali shape: (993, 4)\n",
      "gyro shape: (993, 4)\n",
      "gyro_uncali shape: (993, 4)\n",
      "magn shape: (993, 4)\n",
      "magn_uncali shape: (993, 4)\n",
      "ahrs shape: (993, 4)\n",
      "wifi shape: (3503, 5)\n",
      "ibeacon shape: (20, 3)\n",
      "waypoint shape: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "# path = glob.glob('../input/indoor-location-navigation/test/*.*')[0]\n",
    "# sample_file = read_data_file(path)\n",
    "# sample_file = read_data_file(\"train/5a0546857ecc773753327266/F2/5dccf516c04f060006e6e3c9.txt\")\n",
    "sample_file = read_data_file(\"train/5c3c44b80379370013e0fd2b/F1/5d075ebd4cae4f000a2db4f4.txt\")\n",
    "print('acce shape:', sample_file.acce.shape)\n",
    "print('acce_uncali shape:', sample_file.acce_uncali.shape)\n",
    "print('gyro shape:', sample_file.gyro.shape)\n",
    "print('gyro_uncali shape:', sample_file.gyro_uncali.shape)\n",
    "print('magn shape:', sample_file.magn.shape)\n",
    "print('magn_uncali shape:',sample_file.magn_uncali.shape)\n",
    "print('ahrs shape:', sample_file.ahrs.shape)\n",
    "print('wifi shape:', sample_file.wifi.shape)\n",
    "print('ibeacon shape:', sample_file.ibeacon.shape)\n",
    "print('waypoint shape:', sample_file.waypoint.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['d9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       '89cb11b04122cef23388b0da06bd426c1f48a9b5_cfc84f0752adc96b489f71195d91a946c5f6d3e8_8159618423dfa22f1ca0b62543e2f18eef630ce8',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       '89cb11b04122cef23388b0da06bd426c1f48a9b5_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.ibeacon).iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['d9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       '89cb11b04122cef23388b0da06bd426c1f48a9b5_cfc84f0752adc96b489f71195d91a946c5f6d3e8_8159618423dfa22f1ca0b62543e2f18eef630ce8',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       '89cb11b04122cef23388b0da06bd426c1f48a9b5_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c',\n",
       "       'd9c573b719a17da4836208fc436f87b5ca1aa877_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c_b6589fc6ab0dc82cf12099d1c2d40ab994e8410c'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.ibeacon).iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1560763191901</td>\n",
       "      <td>44aebad0d3851fd527d792ef1af44d24f41b5799</td>\n",
       "      <td>9579076439a10fee78c81db01df9244e4ad62dc2</td>\n",
       "      <td>-47</td>\n",
       "      <td>1560763190640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1560763191901</td>\n",
       "      <td>44aebad0d3851fd527d792ef1af44d24f41b5799</td>\n",
       "      <td>14f6047f681410d9c495eacb6268bb91a7ff048b</td>\n",
       "      <td>-48</td>\n",
       "      <td>1560763190764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1560763191901</td>\n",
       "      <td>44aebad0d3851fd527d792ef1af44d24f41b5799</td>\n",
       "      <td>42d046851e71b041fcf46c993cdc0b3ed0c52465</td>\n",
       "      <td>-48</td>\n",
       "      <td>1560763189850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1560763191901</td>\n",
       "      <td>44aebad0d3851fd527d792ef1af44d24f41b5799</td>\n",
       "      <td>8d00a1a41576014b99ff47e4daf960de25f5b56d</td>\n",
       "      <td>-53</td>\n",
       "      <td>1560763189844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1560763191901</td>\n",
       "      <td>44aebad0d3851fd527d792ef1af44d24f41b5799</td>\n",
       "      <td>3e8fdfc1efbf692cdd39df3a28efc3c6b3c48ea9</td>\n",
       "      <td>-53</td>\n",
       "      <td>1560763177722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>1560763209266</td>\n",
       "      <td>44aebad0d3851fd527d792ef1af44d24f41b5799</td>\n",
       "      <td>da16db279875e6ce30238bc67645af7701d57910</td>\n",
       "      <td>-92</td>\n",
       "      <td>1560763208259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>1560763209266</td>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>bfe2611df418a3bfb2ef229338a176ec0ccc3891</td>\n",
       "      <td>-92</td>\n",
       "      <td>1560763195333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>1560763209266</td>\n",
       "      <td>19773ad19c3753d8a97caae9969e9608d381c21f</td>\n",
       "      <td>ad815b86d3eeec8d7a92c49bbd4aa8811123c4e4</td>\n",
       "      <td>-92</td>\n",
       "      <td>1560763195334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>1560763209266</td>\n",
       "      <td>16928408c28f7988d1f2f23d7525a9f7321167b2</td>\n",
       "      <td>4e9840f8e335f82f57a2642b2f31d882cc28c329</td>\n",
       "      <td>-92</td>\n",
       "      <td>1560763195429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>1560763209266</td>\n",
       "      <td>80929d3a1bb4fee11c62e4be30ef52729a1b8d62</td>\n",
       "      <td>8d7acb42d02eca3efa1ce6b5fb6456ce1e72d946</td>\n",
       "      <td>-92</td>\n",
       "      <td>1560763205866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3503 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                                         1  \\\n",
       "0     1560763191901  44aebad0d3851fd527d792ef1af44d24f41b5799   \n",
       "1     1560763191901  44aebad0d3851fd527d792ef1af44d24f41b5799   \n",
       "2     1560763191901  44aebad0d3851fd527d792ef1af44d24f41b5799   \n",
       "3     1560763191901  44aebad0d3851fd527d792ef1af44d24f41b5799   \n",
       "4     1560763191901  44aebad0d3851fd527d792ef1af44d24f41b5799   \n",
       "...             ...                                       ...   \n",
       "3498  1560763209266  44aebad0d3851fd527d792ef1af44d24f41b5799   \n",
       "3499  1560763209266  da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "3500  1560763209266  19773ad19c3753d8a97caae9969e9608d381c21f   \n",
       "3501  1560763209266  16928408c28f7988d1f2f23d7525a9f7321167b2   \n",
       "3502  1560763209266  80929d3a1bb4fee11c62e4be30ef52729a1b8d62   \n",
       "\n",
       "                                             2    3              4  \n",
       "0     9579076439a10fee78c81db01df9244e4ad62dc2  -47  1560763190640  \n",
       "1     14f6047f681410d9c495eacb6268bb91a7ff048b  -48  1560763190764  \n",
       "2     42d046851e71b041fcf46c993cdc0b3ed0c52465  -48  1560763189850  \n",
       "3     8d00a1a41576014b99ff47e4daf960de25f5b56d  -53  1560763189844  \n",
       "4     3e8fdfc1efbf692cdd39df3a28efc3c6b3c48ea9  -53  1560763177722  \n",
       "...                                        ...  ...            ...  \n",
       "3498  da16db279875e6ce30238bc67645af7701d57910  -92  1560763208259  \n",
       "3499  bfe2611df418a3bfb2ef229338a176ec0ccc3891  -92  1560763195333  \n",
       "3500  ad815b86d3eeec8d7a92c49bbd4aa8811123c4e4  -92  1560763195334  \n",
       "3501  4e9840f8e335f82f57a2642b2f31d882cc28c329  -92  1560763195429  \n",
       "3502  8d7acb42d02eca3efa1ce6b5fb6456ce1e72d946  -92  1560763205866  \n",
       "\n",
       "[3503 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.wifi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1573713058949</td>\n",
       "      <td>2bd871cb979cd9448e2c14df9ccdc1a003b615af</td>\n",
       "      <td>7c572eddccf9b8d9a97e7b1e1c9aa5e0831bb008</td>\n",
       "      <td>-42</td>\n",
       "      <td>1573713057117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573713058949</td>\n",
       "      <td>bb17fdb81a16e158502f7df2335c33e76fdf6df9</td>\n",
       "      <td>6d22a28a88b235942084f24966d6cf59032c2d8e</td>\n",
       "      <td>-49</td>\n",
       "      <td>1573713054395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1573713058949</td>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>296ea9e41acd823ca04a211edefa7cc6457728a4</td>\n",
       "      <td>-51</td>\n",
       "      <td>1573713043813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1573713058949</td>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>fd83a61cb82476f0ad6af28c4cd5872f285fd104</td>\n",
       "      <td>-52</td>\n",
       "      <td>1573713041473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1573713058949</td>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>b550acc32dcc2b1726425312c5bfe19805047b39</td>\n",
       "      <td>-53</td>\n",
       "      <td>1573713043320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>1573713089734</td>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>c84c55562a24f6b83d64df1e7e4c91f838e5a502</td>\n",
       "      <td>-92</td>\n",
       "      <td>1573713077555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>1573713089734</td>\n",
       "      <td>b9f0208be00bd8b337be7f12e02e3a3ce846e22b</td>\n",
       "      <td>964497a251ef2cbd1f8ffc6be6c9b6f9852137e8</td>\n",
       "      <td>-92</td>\n",
       "      <td>1573713077555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>1573713089734</td>\n",
       "      <td>7182afc4e5c212133d5d7d76eb3df6c24618302b</td>\n",
       "      <td>267eaf73afe0e64fd2f330535e9958fdc893a93f</td>\n",
       "      <td>-92</td>\n",
       "      <td>1573713084253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>1573713089734</td>\n",
       "      <td>b9f0208be00bd8b337be7f12e02e3a3ce846e22b</td>\n",
       "      <td>1d067d90fd180e2de69d53c8f42bf26176fcd0f8</td>\n",
       "      <td>-92</td>\n",
       "      <td>1573713084301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>1573713089734</td>\n",
       "      <td>da39a3ee5e6b4b0d3255bfef95601890afd80709</td>\n",
       "      <td>b21bd80e857f993f0385fef27d7636533af87db0</td>\n",
       "      <td>-93</td>\n",
       "      <td>1573713064727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5258 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                                         1  \\\n",
       "0     1573713058949  2bd871cb979cd9448e2c14df9ccdc1a003b615af   \n",
       "1     1573713058949  bb17fdb81a16e158502f7df2335c33e76fdf6df9   \n",
       "2     1573713058949  da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "3     1573713058949  da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "4     1573713058949  da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "...             ...                                       ...   \n",
       "5253  1573713089734  da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "5254  1573713089734  b9f0208be00bd8b337be7f12e02e3a3ce846e22b   \n",
       "5255  1573713089734  7182afc4e5c212133d5d7d76eb3df6c24618302b   \n",
       "5256  1573713089734  b9f0208be00bd8b337be7f12e02e3a3ce846e22b   \n",
       "5257  1573713089734  da39a3ee5e6b4b0d3255bfef95601890afd80709   \n",
       "\n",
       "                                             2    3              4  \n",
       "0     7c572eddccf9b8d9a97e7b1e1c9aa5e0831bb008  -42  1573713057117  \n",
       "1     6d22a28a88b235942084f24966d6cf59032c2d8e  -49  1573713054395  \n",
       "2     296ea9e41acd823ca04a211edefa7cc6457728a4  -51  1573713043813  \n",
       "3     fd83a61cb82476f0ad6af28c4cd5872f285fd104  -52  1573713041473  \n",
       "4     b550acc32dcc2b1726425312c5bfe19805047b39  -53  1573713043320  \n",
       "...                                        ...  ...            ...  \n",
       "5253  c84c55562a24f6b83d64df1e7e4c91f838e5a502  -92  1573713077555  \n",
       "5254  964497a251ef2cbd1f8ffc6be6c9b6f9852137e8  -92  1573713077555  \n",
       "5255  267eaf73afe0e64fd2f330535e9958fdc893a93f  -92  1573713084253  \n",
       "5256  1d067d90fd180e2de69d53c8f42bf26176fcd0f8  -92  1573713084301  \n",
       "5257  b21bd80e857f993f0385fef27d7636533af87db0  -93  1573713064727  \n",
       "\n",
       "[5258 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.wifi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1573713056962.0</td>\n",
       "      <td>-0.40789795000000000913</td>\n",
       "      <td>3.20840449999999988151</td>\n",
       "      <td>9.37954700000000052285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573713056982.0</td>\n",
       "      <td>-0.13494872999999998897</td>\n",
       "      <td>3.19224549999999984706</td>\n",
       "      <td>9.20477299999999942770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1573713057002.0</td>\n",
       "      <td>-0.07989501999999999715</td>\n",
       "      <td>2.98693849999999994083</td>\n",
       "      <td>9.89788800000000001944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1573713057022.0</td>\n",
       "      <td>0.00450134299999999966</td>\n",
       "      <td>2.74452199999999990609</td>\n",
       "      <td>10.97109999999999985221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1573713057042.0</td>\n",
       "      <td>0.11943054000000000170</td>\n",
       "      <td>2.83250430000000008590</td>\n",
       "      <td>11.46968099999999957106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>1573713091388.0</td>\n",
       "      <td>0.56893919999999997827</td>\n",
       "      <td>3.06893919999999997827</td>\n",
       "      <td>8.80972299999999997056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1573713091408.0</td>\n",
       "      <td>0.35585021999999999487</td>\n",
       "      <td>3.19462590000000012935</td>\n",
       "      <td>8.68223599999999962051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1573713091428.0</td>\n",
       "      <td>0.28642273000000001426</td>\n",
       "      <td>3.35205080000000021911</td>\n",
       "      <td>8.45777900000000038006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1573713091448.0</td>\n",
       "      <td>0.53482056000000000040</td>\n",
       "      <td>3.38975520000000019039</td>\n",
       "      <td>8.49488799999999955048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1573713091467.0</td>\n",
       "      <td>0.62579346000000002359</td>\n",
       "      <td>3.31134029999999990324</td>\n",
       "      <td>8.77500900000000072509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                       1                       2  \\\n",
       "0     1573713056962.0 -0.40789795000000000913  3.20840449999999988151   \n",
       "1     1573713056982.0 -0.13494872999999998897  3.19224549999999984706   \n",
       "2     1573713057002.0 -0.07989501999999999715  2.98693849999999994083   \n",
       "3     1573713057022.0  0.00450134299999999966  2.74452199999999990609   \n",
       "4     1573713057042.0  0.11943054000000000170  2.83250430000000008590   \n",
       "...               ...                     ...                     ...   \n",
       "1738  1573713091388.0  0.56893919999999997827  3.06893919999999997827   \n",
       "1739  1573713091408.0  0.35585021999999999487  3.19462590000000012935   \n",
       "1740  1573713091428.0  0.28642273000000001426  3.35205080000000021911   \n",
       "1741  1573713091448.0  0.53482056000000000040  3.38975520000000019039   \n",
       "1742  1573713091467.0  0.62579346000000002359  3.31134029999999990324   \n",
       "\n",
       "                            3  \n",
       "0      9.37954700000000052285  \n",
       "1      9.20477299999999942770  \n",
       "2      9.89788800000000001944  \n",
       "3     10.97109999999999985221  \n",
       "4     11.46968099999999957106  \n",
       "...                       ...  \n",
       "1738   8.80972299999999997056  \n",
       "1739   8.68223599999999962051  \n",
       "1740   8.45777900000000038006  \n",
       "1741   8.49488799999999955048  \n",
       "1742   8.77500900000000072509  \n",
       "\n",
       "[1743 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.acce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1573713056859.0</td>\n",
       "      <td>46.30242499999999949978</td>\n",
       "      <td>56.80776000000000180989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573713071518.0</td>\n",
       "      <td>34.11689799999999905822</td>\n",
       "      <td>47.21352999999999866532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1573713075930.0</td>\n",
       "      <td>30.15529400000000137538</td>\n",
       "      <td>48.92016000000000275350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1573713082472.0</td>\n",
       "      <td>25.32438300000000097612</td>\n",
       "      <td>47.50362799999999907641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1573713086997.0</td>\n",
       "      <td>23.94379800000000102500</td>\n",
       "      <td>51.76706699999999727879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1573713090934.0</td>\n",
       "      <td>19.68363799999999841361</td>\n",
       "      <td>54.20067999999999841521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                        1                        2\n",
       "0  1573713056859.0  46.30242499999999949978  56.80776000000000180989\n",
       "1  1573713071518.0  34.11689799999999905822  47.21352999999999866532\n",
       "2  1573713075930.0  30.15529400000000137538  48.92016000000000275350\n",
       "3  1573713082472.0  25.32438300000000097612  47.50362799999999907641\n",
       "4  1573713086997.0  23.94379800000000102500  51.76706699999999727879\n",
       "5  1573713090934.0  19.68363799999999841361  54.20067999999999841521"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.waypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1573713056962.0</td>\n",
       "      <td>0.11967468000000000550</td>\n",
       "      <td>0.11813354500000000646</td>\n",
       "      <td>-0.16870117000000001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573713056982.0</td>\n",
       "      <td>0.13404846000000000816</td>\n",
       "      <td>-0.11994934000000000152</td>\n",
       "      <td>-0.17668152000000000856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1573713057002.0</td>\n",
       "      <td>-0.07049560500000000285</td>\n",
       "      <td>-0.23074341000000000990</td>\n",
       "      <td>-0.20864868000000000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1573713057022.0</td>\n",
       "      <td>-0.31816100000000002712</td>\n",
       "      <td>-0.18280029999999999890</td>\n",
       "      <td>-0.22036743000000000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1573713057042.0</td>\n",
       "      <td>-0.37194823999999998554</td>\n",
       "      <td>-0.06723022500000000456</td>\n",
       "      <td>-0.17402649000000000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1573713057061.0</td>\n",
       "      <td>-0.21643065999999999693</td>\n",
       "      <td>0.08992004400000000452</td>\n",
       "      <td>-0.11010741999999999752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1573713057081.0</td>\n",
       "      <td>0.01155090299999999952</td>\n",
       "      <td>0.33172606999999998401</td>\n",
       "      <td>-0.02488708499999999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1573713057101.0</td>\n",
       "      <td>0.07705688500000000551</td>\n",
       "      <td>0.35249330000000000940</td>\n",
       "      <td>0.01187133800000000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1573713057121.0</td>\n",
       "      <td>-0.04331970200000000160</td>\n",
       "      <td>0.17886352999999999280</td>\n",
       "      <td>-0.00997924799999999959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1573713057141.0</td>\n",
       "      <td>-0.10244751000000000551</td>\n",
       "      <td>0.14477539000000000380</td>\n",
       "      <td>-0.00518798829999999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1573713057160.0</td>\n",
       "      <td>0.03871154799999999840</td>\n",
       "      <td>0.22892761000000000360</td>\n",
       "      <td>0.04968261699999999836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1573713057180.0</td>\n",
       "      <td>0.17240906000000000287</td>\n",
       "      <td>0.26461792000000000646</td>\n",
       "      <td>0.12052917500000000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1573713057200.0</td>\n",
       "      <td>0.16600037000000000820</td>\n",
       "      <td>0.14051818999999998727</td>\n",
       "      <td>0.14076232999999999107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1573713057220.0</td>\n",
       "      <td>0.12020873999999999449</td>\n",
       "      <td>-0.07360840000000000438</td>\n",
       "      <td>0.08856200999999999657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1573713057240.0</td>\n",
       "      <td>0.20648193000000000796</td>\n",
       "      <td>-0.22169495000000000173</td>\n",
       "      <td>0.06193542500000000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1573713057259.0</td>\n",
       "      <td>0.47067259999999999653</td>\n",
       "      <td>-0.09704590000000000438</td>\n",
       "      <td>0.14289856000000000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1573713057279.0</td>\n",
       "      <td>0.71675109999999997434</td>\n",
       "      <td>0.25236510000000000886</td>\n",
       "      <td>0.22705078000000000760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1573713057299.0</td>\n",
       "      <td>0.72421265000000001333</td>\n",
       "      <td>0.33491515999999998954</td>\n",
       "      <td>0.32772826999999998820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1573713057319.0</td>\n",
       "      <td>0.55482480000000000686</td>\n",
       "      <td>0.16874695000000000666</td>\n",
       "      <td>0.34584045000000002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1573713057339.0</td>\n",
       "      <td>0.22512816999999998857</td>\n",
       "      <td>-0.20411682000000000436</td>\n",
       "      <td>0.21372985999999999374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1573713057358.0</td>\n",
       "      <td>-0.10670470999999999429</td>\n",
       "      <td>-0.46563719999999997334</td>\n",
       "      <td>0.05874633800000000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1573713057378.0</td>\n",
       "      <td>-0.21163940000000000530</td>\n",
       "      <td>-0.50877380000000005378</td>\n",
       "      <td>-0.00784301800000000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1573713057398.0</td>\n",
       "      <td>-0.04598999000000000142</td>\n",
       "      <td>-0.43261719999999997954</td>\n",
       "      <td>0.03796386699999999836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1573713057418.0</td>\n",
       "      <td>0.18305968999999999713</td>\n",
       "      <td>-0.25683593999999998481</td>\n",
       "      <td>0.15196228000000000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1573713057438.0</td>\n",
       "      <td>0.26507567999999998021</td>\n",
       "      <td>-0.11302184999999999315</td>\n",
       "      <td>0.18870544000000000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1573713057457.0</td>\n",
       "      <td>0.15962218999999999713</td>\n",
       "      <td>-0.05177306999999999743</td>\n",
       "      <td>0.11732483000000000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1573713057477.0</td>\n",
       "      <td>-0.03533935500000000285</td>\n",
       "      <td>-0.08479309000000000152</td>\n",
       "      <td>0.04649352999999999819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1573713057497.0</td>\n",
       "      <td>-0.14079284999999999717</td>\n",
       "      <td>-0.13166808999999998764</td>\n",
       "      <td>0.01879882800000000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1573713057517.0</td>\n",
       "      <td>-0.16157531999999999450</td>\n",
       "      <td>-0.21263123000000000440</td>\n",
       "      <td>0.05342101999999999962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1573713057537.0</td>\n",
       "      <td>-0.13972472999999999144</td>\n",
       "      <td>-0.26376343000000002093</td>\n",
       "      <td>0.12425231999999999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1573713057557.0</td>\n",
       "      <td>-0.05078125000000000000</td>\n",
       "      <td>-0.21688842999999999317</td>\n",
       "      <td>0.17272949000000001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1573713057576.0</td>\n",
       "      <td>0.10635376000000000551</td>\n",
       "      <td>-0.18119811999999999030</td>\n",
       "      <td>0.17858887000000001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1573713057596.0</td>\n",
       "      <td>0.28211975000000000247</td>\n",
       "      <td>-0.18013000000000001233</td>\n",
       "      <td>0.18603516000000000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1573713057616.0</td>\n",
       "      <td>0.37533569999999999434</td>\n",
       "      <td>-0.03791809000000000152</td>\n",
       "      <td>0.18870544000000000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1573713057636.0</td>\n",
       "      <td>0.27307130000000001679</td>\n",
       "      <td>0.05102538999999999686</td>\n",
       "      <td>0.16047668000000001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1573713057656.0</td>\n",
       "      <td>-0.03106689500000000062</td>\n",
       "      <td>-0.05551147499999999763</td>\n",
       "      <td>0.10134888000000000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1573713057675.0</td>\n",
       "      <td>-0.39645385999999999127</td>\n",
       "      <td>-0.55618285999999994562</td>\n",
       "      <td>0.00334167480000000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1573713057695.0</td>\n",
       "      <td>-0.52162169999999996595</td>\n",
       "      <td>-0.38360596000000002359</td>\n",
       "      <td>0.01293945300000000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1573713057715.0</td>\n",
       "      <td>-0.38473509999999999653</td>\n",
       "      <td>0.25448608000000000340</td>\n",
       "      <td>0.18338013000000000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1573713057735.0</td>\n",
       "      <td>-0.24412537000000000820</td>\n",
       "      <td>0.33226012999999998687</td>\n",
       "      <td>0.22119140000000001023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1573713057755.0</td>\n",
       "      <td>-0.36875915999999997474</td>\n",
       "      <td>-0.07894897500000000456</td>\n",
       "      <td>0.17379759999999999653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1573713057774.0</td>\n",
       "      <td>-0.53015137000000001066</td>\n",
       "      <td>-0.32875060000000000393</td>\n",
       "      <td>0.12532043000000001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1573713057794.0</td>\n",
       "      <td>-0.46250915999999997474</td>\n",
       "      <td>-0.31596374999999998767</td>\n",
       "      <td>0.04649352999999999819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1573713057814.0</td>\n",
       "      <td>-0.14453125000000000000</td>\n",
       "      <td>-0.14125060999999999867</td>\n",
       "      <td>-0.03074645999999999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1573713057834.0</td>\n",
       "      <td>0.26188660000000002492</td>\n",
       "      <td>0.01374816899999999932</td>\n",
       "      <td>-0.09786986999999999770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1573713057854.0</td>\n",
       "      <td>0.57933044000000000207</td>\n",
       "      <td>0.04783630400000000310</td>\n",
       "      <td>-0.14579772999999998651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1573713057873.0</td>\n",
       "      <td>0.70663450000000005424</td>\n",
       "      <td>-0.12315368999999999622</td>\n",
       "      <td>-0.19213867000000001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1573713057893.0</td>\n",
       "      <td>0.59902953999999997148</td>\n",
       "      <td>-0.23126220000000000110</td>\n",
       "      <td>-0.27468871999999999733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1573713057913.0</td>\n",
       "      <td>0.30769348000000001919</td>\n",
       "      <td>-0.10609435999999999867</td>\n",
       "      <td>-0.34606934000000000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1573713057933.0</td>\n",
       "      <td>0.03924560500000000285</td>\n",
       "      <td>0.08245849600000000612</td>\n",
       "      <td>-0.38069153000000000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1573713057953.0</td>\n",
       "      <td>-0.08593750000000000000</td>\n",
       "      <td>0.15649414000000000380</td>\n",
       "      <td>-0.35192869999999998321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1573713057973.0</td>\n",
       "      <td>-0.04438781700000000302</td>\n",
       "      <td>0.18472289999999999544</td>\n",
       "      <td>-0.26724242999999997528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1573713057992.0</td>\n",
       "      <td>0.05096435500000000285</td>\n",
       "      <td>0.27261352999999999280</td>\n",
       "      <td>-0.18627930000000000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1573713058012.0</td>\n",
       "      <td>0.08291626000000000551</td>\n",
       "      <td>0.41908264000000000626</td>\n",
       "      <td>-0.11650085400000000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1573713058032.0</td>\n",
       "      <td>0.12286376999999999715</td>\n",
       "      <td>0.39511108000000000340</td>\n",
       "      <td>-0.03234863300000000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1573713058052.0</td>\n",
       "      <td>0.19956969999999998877</td>\n",
       "      <td>0.16447449000000000097</td>\n",
       "      <td>-0.00570678699999999962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1573713058072.0</td>\n",
       "      <td>0.21873474000000001083</td>\n",
       "      <td>-0.10983276000000000150</td>\n",
       "      <td>-0.05737304700000000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1573713058091.0</td>\n",
       "      <td>0.07386779999999999735</td>\n",
       "      <td>-0.29519653000000001253</td>\n",
       "      <td>-0.15856934000000000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1573713058111.0</td>\n",
       "      <td>-0.07315063500000000551</td>\n",
       "      <td>-0.30210875999999997621</td>\n",
       "      <td>-0.25657654000000001959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1573713058131.0</td>\n",
       "      <td>-0.21749878000000000267</td>\n",
       "      <td>-0.23979186999999999030</td>\n",
       "      <td>-0.26831054999999998101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1573713058151.0</td>\n",
       "      <td>-0.33201599999999997781</td>\n",
       "      <td>-0.21635436999999999030</td>\n",
       "      <td>-0.26084899999999999753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1573713058171.0</td>\n",
       "      <td>-0.35064697000000000227</td>\n",
       "      <td>-0.20837401999999999314</td>\n",
       "      <td>-0.20118712999999999180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1573713058190.0</td>\n",
       "      <td>-0.27395629999999998594</td>\n",
       "      <td>-0.03526305999999999885</td>\n",
       "      <td>-0.10957336400000000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1573713058210.0</td>\n",
       "      <td>-0.19566344999999998877</td>\n",
       "      <td>0.25343323000000000933</td>\n",
       "      <td>0.02784729000000000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1573713058230.0</td>\n",
       "      <td>-0.18074035999999998880</td>\n",
       "      <td>0.32853700000000002346</td>\n",
       "      <td>0.02198791500000000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1573713058250.0</td>\n",
       "      <td>-0.17860412999999999983</td>\n",
       "      <td>0.28858948000000000933</td>\n",
       "      <td>0.00706481929999999963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1573713058270.0</td>\n",
       "      <td>-0.20098877000000001103</td>\n",
       "      <td>0.09204101600000000327</td>\n",
       "      <td>-0.07281493999999999467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1573713058289.0</td>\n",
       "      <td>-0.27714539999999998621</td>\n",
       "      <td>-0.09172057999999999600</td>\n",
       "      <td>-0.23687743999999999467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1573713058309.0</td>\n",
       "      <td>-0.38740540000000001086</td>\n",
       "      <td>-0.12847900000000000986</td>\n",
       "      <td>-0.35299682999999998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1573713058329.0</td>\n",
       "      <td>-0.48434448000000002166</td>\n",
       "      <td>-0.12155151000000000150</td>\n",
       "      <td>-0.38920592999999997774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1573713058349.0</td>\n",
       "      <td>-0.51948550000000004445</td>\n",
       "      <td>-0.15191650000000000986</td>\n",
       "      <td>-0.41050720000000001653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1573713058369.0</td>\n",
       "      <td>-0.43374634000000000800</td>\n",
       "      <td>-0.08160400399999999388</td>\n",
       "      <td>-0.40359496999999999733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1573713058388.0</td>\n",
       "      <td>-0.17169190000000000840</td>\n",
       "      <td>0.20123290999999998707</td>\n",
       "      <td>-0.25871276999999998081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1573713058408.0</td>\n",
       "      <td>0.10475159000000000553</td>\n",
       "      <td>0.45423890000000000100</td>\n",
       "      <td>0.00601196300000000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1573713058428.0</td>\n",
       "      <td>0.29597473000000001919</td>\n",
       "      <td>0.61933899999999997288</td>\n",
       "      <td>0.21693419999999999370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1573713058448.0</td>\n",
       "      <td>0.42221069999999999434</td>\n",
       "      <td>0.65556334999999998914</td>\n",
       "      <td>0.31121826000000002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1573713058468.0</td>\n",
       "      <td>0.44458007999999998860</td>\n",
       "      <td>0.40043640000000002566</td>\n",
       "      <td>0.31494139999999998247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1573713058488.0</td>\n",
       "      <td>0.35562134000000000800</td>\n",
       "      <td>-0.02140808099999999894</td>\n",
       "      <td>0.17752075000000000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1573713058507.0</td>\n",
       "      <td>0.22140503000000000267</td>\n",
       "      <td>-0.24404907000000000683</td>\n",
       "      <td>0.00920105000000000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1573713058527.0</td>\n",
       "      <td>0.08717345999999999429</td>\n",
       "      <td>-0.22434998000000000440</td>\n",
       "      <td>-0.09945679000000000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1573713058547.0</td>\n",
       "      <td>-0.00657653799999999983</td>\n",
       "      <td>-0.20251464999999999050</td>\n",
       "      <td>-0.11703491000000000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1573713058567.0</td>\n",
       "      <td>-0.04119873000000000285</td>\n",
       "      <td>-0.23446654999999999580</td>\n",
       "      <td>-0.08560181000000000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1573713058587.0</td>\n",
       "      <td>-0.01455688500000000031</td>\n",
       "      <td>-0.21476745999999999337</td>\n",
       "      <td>-0.03713989300000000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1573713058606.0</td>\n",
       "      <td>0.03018188499999999858</td>\n",
       "      <td>-0.12741088999999999887</td>\n",
       "      <td>0.01559448199999999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1573713058626.0</td>\n",
       "      <td>0.07812500000000000000</td>\n",
       "      <td>-0.00064086913999999995</td>\n",
       "      <td>0.06567383000000000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1573713058646.0</td>\n",
       "      <td>0.13085937999999999737</td>\n",
       "      <td>0.06381225599999999776</td>\n",
       "      <td>0.09388733000000000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1573713058666.0</td>\n",
       "      <td>0.15802002000000001103</td>\n",
       "      <td>0.06648254400000000452</td>\n",
       "      <td>0.13543700999999999657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1573713058686.0</td>\n",
       "      <td>0.15748596000000000816</td>\n",
       "      <td>0.02653503399999999901</td>\n",
       "      <td>0.14396666999999999104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1573713058705.0</td>\n",
       "      <td>0.08772278000000000020</td>\n",
       "      <td>-0.19132995999999999337</td>\n",
       "      <td>0.06726073999999999942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1573713058725.0</td>\n",
       "      <td>-0.00497436519999999976</td>\n",
       "      <td>-0.39106750000000001233</td>\n",
       "      <td>-0.06802368000000000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1573713058745.0</td>\n",
       "      <td>-0.05822754000000000124</td>\n",
       "      <td>-0.41448974999999999014</td>\n",
       "      <td>-0.16177368000000000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1573713058765.0</td>\n",
       "      <td>-0.03692626999999999715</td>\n",
       "      <td>-0.35697937000000001806</td>\n",
       "      <td>-0.18255615000000000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1573713058785.0</td>\n",
       "      <td>0.02859497000000000080</td>\n",
       "      <td>-0.23393249999999998767</td>\n",
       "      <td>-0.18627930000000000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1573713058804.0</td>\n",
       "      <td>0.03231811500000000142</td>\n",
       "      <td>-0.16256713999999999887</td>\n",
       "      <td>-0.21769714000000001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1573713058824.0</td>\n",
       "      <td>-0.04278564499999999715</td>\n",
       "      <td>-0.30850220000000000420</td>\n",
       "      <td>-0.30558776999999998081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1573713058844.0</td>\n",
       "      <td>-0.12002563500000000551</td>\n",
       "      <td>-0.49758910000000000640</td>\n",
       "      <td>-0.39985657000000002226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1573713058864.0</td>\n",
       "      <td>-0.21696471999999999980</td>\n",
       "      <td>-0.49972534000000001786</td>\n",
       "      <td>-0.40252685999999998634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1573713058884.0</td>\n",
       "      <td>-0.33467101999999998574</td>\n",
       "      <td>-0.25523375999999997621</td>\n",
       "      <td>-0.29440307999999998367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1573713058903.0</td>\n",
       "      <td>-0.44653320000000001899</td>\n",
       "      <td>-0.08746337999999999335</td>\n",
       "      <td>-0.14686583999999999750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1573713058923.0</td>\n",
       "      <td>-0.57223509999999999653</td>\n",
       "      <td>-0.36016846000000002359</td>\n",
       "      <td>-0.10266113000000000322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                       1                       2  \\\n",
       "0   1573713056962.0  0.11967468000000000550  0.11813354500000000646   \n",
       "1   1573713056982.0  0.13404846000000000816 -0.11994934000000000152   \n",
       "2   1573713057002.0 -0.07049560500000000285 -0.23074341000000000990   \n",
       "3   1573713057022.0 -0.31816100000000002712 -0.18280029999999999890   \n",
       "4   1573713057042.0 -0.37194823999999998554 -0.06723022500000000456   \n",
       "5   1573713057061.0 -0.21643065999999999693  0.08992004400000000452   \n",
       "6   1573713057081.0  0.01155090299999999952  0.33172606999999998401   \n",
       "7   1573713057101.0  0.07705688500000000551  0.35249330000000000940   \n",
       "8   1573713057121.0 -0.04331970200000000160  0.17886352999999999280   \n",
       "9   1573713057141.0 -0.10244751000000000551  0.14477539000000000380   \n",
       "10  1573713057160.0  0.03871154799999999840  0.22892761000000000360   \n",
       "11  1573713057180.0  0.17240906000000000287  0.26461792000000000646   \n",
       "12  1573713057200.0  0.16600037000000000820  0.14051818999999998727   \n",
       "13  1573713057220.0  0.12020873999999999449 -0.07360840000000000438   \n",
       "14  1573713057240.0  0.20648193000000000796 -0.22169495000000000173   \n",
       "15  1573713057259.0  0.47067259999999999653 -0.09704590000000000438   \n",
       "16  1573713057279.0  0.71675109999999997434  0.25236510000000000886   \n",
       "17  1573713057299.0  0.72421265000000001333  0.33491515999999998954   \n",
       "18  1573713057319.0  0.55482480000000000686  0.16874695000000000666   \n",
       "19  1573713057339.0  0.22512816999999998857 -0.20411682000000000436   \n",
       "20  1573713057358.0 -0.10670470999999999429 -0.46563719999999997334   \n",
       "21  1573713057378.0 -0.21163940000000000530 -0.50877380000000005378   \n",
       "22  1573713057398.0 -0.04598999000000000142 -0.43261719999999997954   \n",
       "23  1573713057418.0  0.18305968999999999713 -0.25683593999999998481   \n",
       "24  1573713057438.0  0.26507567999999998021 -0.11302184999999999315   \n",
       "25  1573713057457.0  0.15962218999999999713 -0.05177306999999999743   \n",
       "26  1573713057477.0 -0.03533935500000000285 -0.08479309000000000152   \n",
       "27  1573713057497.0 -0.14079284999999999717 -0.13166808999999998764   \n",
       "28  1573713057517.0 -0.16157531999999999450 -0.21263123000000000440   \n",
       "29  1573713057537.0 -0.13972472999999999144 -0.26376343000000002093   \n",
       "30  1573713057557.0 -0.05078125000000000000 -0.21688842999999999317   \n",
       "31  1573713057576.0  0.10635376000000000551 -0.18119811999999999030   \n",
       "32  1573713057596.0  0.28211975000000000247 -0.18013000000000001233   \n",
       "33  1573713057616.0  0.37533569999999999434 -0.03791809000000000152   \n",
       "34  1573713057636.0  0.27307130000000001679  0.05102538999999999686   \n",
       "35  1573713057656.0 -0.03106689500000000062 -0.05551147499999999763   \n",
       "36  1573713057675.0 -0.39645385999999999127 -0.55618285999999994562   \n",
       "37  1573713057695.0 -0.52162169999999996595 -0.38360596000000002359   \n",
       "38  1573713057715.0 -0.38473509999999999653  0.25448608000000000340   \n",
       "39  1573713057735.0 -0.24412537000000000820  0.33226012999999998687   \n",
       "40  1573713057755.0 -0.36875915999999997474 -0.07894897500000000456   \n",
       "41  1573713057774.0 -0.53015137000000001066 -0.32875060000000000393   \n",
       "42  1573713057794.0 -0.46250915999999997474 -0.31596374999999998767   \n",
       "43  1573713057814.0 -0.14453125000000000000 -0.14125060999999999867   \n",
       "44  1573713057834.0  0.26188660000000002492  0.01374816899999999932   \n",
       "45  1573713057854.0  0.57933044000000000207  0.04783630400000000310   \n",
       "46  1573713057873.0  0.70663450000000005424 -0.12315368999999999622   \n",
       "47  1573713057893.0  0.59902953999999997148 -0.23126220000000000110   \n",
       "48  1573713057913.0  0.30769348000000001919 -0.10609435999999999867   \n",
       "49  1573713057933.0  0.03924560500000000285  0.08245849600000000612   \n",
       "50  1573713057953.0 -0.08593750000000000000  0.15649414000000000380   \n",
       "51  1573713057973.0 -0.04438781700000000302  0.18472289999999999544   \n",
       "52  1573713057992.0  0.05096435500000000285  0.27261352999999999280   \n",
       "53  1573713058012.0  0.08291626000000000551  0.41908264000000000626   \n",
       "54  1573713058032.0  0.12286376999999999715  0.39511108000000000340   \n",
       "55  1573713058052.0  0.19956969999999998877  0.16447449000000000097   \n",
       "56  1573713058072.0  0.21873474000000001083 -0.10983276000000000150   \n",
       "57  1573713058091.0  0.07386779999999999735 -0.29519653000000001253   \n",
       "58  1573713058111.0 -0.07315063500000000551 -0.30210875999999997621   \n",
       "59  1573713058131.0 -0.21749878000000000267 -0.23979186999999999030   \n",
       "60  1573713058151.0 -0.33201599999999997781 -0.21635436999999999030   \n",
       "61  1573713058171.0 -0.35064697000000000227 -0.20837401999999999314   \n",
       "62  1573713058190.0 -0.27395629999999998594 -0.03526305999999999885   \n",
       "63  1573713058210.0 -0.19566344999999998877  0.25343323000000000933   \n",
       "64  1573713058230.0 -0.18074035999999998880  0.32853700000000002346   \n",
       "65  1573713058250.0 -0.17860412999999999983  0.28858948000000000933   \n",
       "66  1573713058270.0 -0.20098877000000001103  0.09204101600000000327   \n",
       "67  1573713058289.0 -0.27714539999999998621 -0.09172057999999999600   \n",
       "68  1573713058309.0 -0.38740540000000001086 -0.12847900000000000986   \n",
       "69  1573713058329.0 -0.48434448000000002166 -0.12155151000000000150   \n",
       "70  1573713058349.0 -0.51948550000000004445 -0.15191650000000000986   \n",
       "71  1573713058369.0 -0.43374634000000000800 -0.08160400399999999388   \n",
       "72  1573713058388.0 -0.17169190000000000840  0.20123290999999998707   \n",
       "73  1573713058408.0  0.10475159000000000553  0.45423890000000000100   \n",
       "74  1573713058428.0  0.29597473000000001919  0.61933899999999997288   \n",
       "75  1573713058448.0  0.42221069999999999434  0.65556334999999998914   \n",
       "76  1573713058468.0  0.44458007999999998860  0.40043640000000002566   \n",
       "77  1573713058488.0  0.35562134000000000800 -0.02140808099999999894   \n",
       "78  1573713058507.0  0.22140503000000000267 -0.24404907000000000683   \n",
       "79  1573713058527.0  0.08717345999999999429 -0.22434998000000000440   \n",
       "80  1573713058547.0 -0.00657653799999999983 -0.20251464999999999050   \n",
       "81  1573713058567.0 -0.04119873000000000285 -0.23446654999999999580   \n",
       "82  1573713058587.0 -0.01455688500000000031 -0.21476745999999999337   \n",
       "83  1573713058606.0  0.03018188499999999858 -0.12741088999999999887   \n",
       "84  1573713058626.0  0.07812500000000000000 -0.00064086913999999995   \n",
       "85  1573713058646.0  0.13085937999999999737  0.06381225599999999776   \n",
       "86  1573713058666.0  0.15802002000000001103  0.06648254400000000452   \n",
       "87  1573713058686.0  0.15748596000000000816  0.02653503399999999901   \n",
       "88  1573713058705.0  0.08772278000000000020 -0.19132995999999999337   \n",
       "89  1573713058725.0 -0.00497436519999999976 -0.39106750000000001233   \n",
       "90  1573713058745.0 -0.05822754000000000124 -0.41448974999999999014   \n",
       "91  1573713058765.0 -0.03692626999999999715 -0.35697937000000001806   \n",
       "92  1573713058785.0  0.02859497000000000080 -0.23393249999999998767   \n",
       "93  1573713058804.0  0.03231811500000000142 -0.16256713999999999887   \n",
       "94  1573713058824.0 -0.04278564499999999715 -0.30850220000000000420   \n",
       "95  1573713058844.0 -0.12002563500000000551 -0.49758910000000000640   \n",
       "96  1573713058864.0 -0.21696471999999999980 -0.49972534000000001786   \n",
       "97  1573713058884.0 -0.33467101999999998574 -0.25523375999999997621   \n",
       "98  1573713058903.0 -0.44653320000000001899 -0.08746337999999999335   \n",
       "99  1573713058923.0 -0.57223509999999999653 -0.36016846000000002359   \n",
       "\n",
       "                         3  \n",
       "0  -0.16870117000000001140  \n",
       "1  -0.17668152000000000856  \n",
       "2  -0.20864868000000000303  \n",
       "3  -0.22036743000000000303  \n",
       "4  -0.17402649000000000590  \n",
       "5  -0.11010741999999999752  \n",
       "6  -0.02488708499999999976  \n",
       "7   0.01187133800000000038  \n",
       "8  -0.00997924799999999959  \n",
       "9  -0.00518798829999999982  \n",
       "10  0.04968261699999999836  \n",
       "11  0.12052917500000000228  \n",
       "12  0.14076232999999999107  \n",
       "13  0.08856200999999999657  \n",
       "14  0.06193542500000000228  \n",
       "15  0.14289856000000000780  \n",
       "16  0.22705078000000000760  \n",
       "17  0.32772826999999998820  \n",
       "18  0.34584045000000002146  \n",
       "19  0.21372985999999999374  \n",
       "20  0.05874633800000000211  \n",
       "21 -0.00784301800000000021  \n",
       "22  0.03796386699999999836  \n",
       "23  0.15196228000000000513  \n",
       "24  0.18870544000000000207  \n",
       "25  0.11732483000000000495  \n",
       "26  0.04649352999999999819  \n",
       "27  0.01879882800000000007  \n",
       "28  0.05342101999999999962  \n",
       "29  0.12425231999999999943  \n",
       "30  0.17272949000000001329  \n",
       "31  0.17858887000000001066  \n",
       "32  0.18603516000000000497  \n",
       "33  0.18870544000000000207  \n",
       "34  0.16047668000000001043  \n",
       "35  0.10134888000000000230  \n",
       "36  0.00334167480000000005  \n",
       "37  0.01293945300000000007  \n",
       "38  0.18338013000000000230  \n",
       "39  0.22119140000000001023  \n",
       "40  0.17379759999999999653  \n",
       "41  0.12532043000000001043  \n",
       "42  0.04649352999999999819  \n",
       "43 -0.03074645999999999976  \n",
       "44 -0.09786986999999999770  \n",
       "45 -0.14579772999999998651  \n",
       "46 -0.19213867000000001140  \n",
       "47 -0.27468871999999999733  \n",
       "48 -0.34606934000000000307  \n",
       "49 -0.38069153000000000020  \n",
       "50 -0.35192869999999998321  \n",
       "51 -0.26724242999999997528  \n",
       "52 -0.18627930000000000876  \n",
       "53 -0.11650085400000000091  \n",
       "54 -0.03234863300000000164  \n",
       "55 -0.00570678699999999962  \n",
       "56 -0.05737304700000000340  \n",
       "57 -0.15856934000000000307  \n",
       "58 -0.25657654000000001959  \n",
       "59 -0.26831054999999998101  \n",
       "60 -0.26084899999999999753  \n",
       "61 -0.20118712999999999180  \n",
       "62 -0.10957336400000000642  \n",
       "63  0.02784729000000000024  \n",
       "64  0.02198791500000000024  \n",
       "65  0.00706481929999999963  \n",
       "66 -0.07281493999999999467  \n",
       "67 -0.23687743999999999467  \n",
       "68 -0.35299682999999998367  \n",
       "69 -0.38920592999999997774  \n",
       "70 -0.41050720000000001653  \n",
       "71 -0.40359496999999999733  \n",
       "72 -0.25871276999999998081  \n",
       "73  0.00601196300000000038  \n",
       "74  0.21693419999999999370  \n",
       "75  0.31121826000000002432  \n",
       "76  0.31494139999999998247  \n",
       "77  0.17752075000000000493  \n",
       "78  0.00920105000000000055  \n",
       "79 -0.09945679000000000325  \n",
       "80 -0.11703491000000000588  \n",
       "81 -0.08560181000000000040  \n",
       "82 -0.03713989300000000021  \n",
       "83  0.01559448199999999979  \n",
       "84  0.06567383000000000248  \n",
       "85  0.09388733000000000495  \n",
       "86  0.13543700999999999657  \n",
       "87  0.14396666999999999104  \n",
       "88  0.06726073999999999942  \n",
       "89 -0.06802368000000000303  \n",
       "90 -0.16177368000000000303  \n",
       "91 -0.18255615000000000037  \n",
       "92 -0.18627930000000000876  \n",
       "93 -0.21769714000000001120  \n",
       "94 -0.30558776999999998081  \n",
       "95 -0.39985657000000002226  \n",
       "96 -0.40252685999999998634  \n",
       "97 -0.29440307999999998367  \n",
       "98 -0.14686583999999999750  \n",
       "99 -0.10266113000000000322  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.gyro).iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa153972198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.gyro).iloc[:100].iloc[:, 1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa15394f9b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.gyro).iloc[:100].iloc[:, 2].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa1538b0438>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(sample_file.acce).iloc[:100].iloc[:, 3].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensor_df(rd, start_time, site_id, floor_id, unique_id):\n",
    "    df = pd.DataFrame(rd)\n",
    "    df.loc[:, 0] = df.loc[:, 0].astype(float)\n",
    "    df['time_delta'] = df.loc[:, 0] - start_time\n",
    "#     df['ts'] = pd.to_datetime((df.loc[:, 0] - start_time) * 1000000)\n",
    "    df['site'] = site_id\n",
    "    df['floor'] = floor_id   \n",
    "    df['uid'] = unique_id\n",
    "    df = df.drop(0, axis=1)\n",
    "    return df\n",
    "\n",
    "def parse_path_file(site_split, idx=\"\"):\n",
    "    df_acce = pd.DataFrame()\n",
    "    df_acce_uncali = pd.DataFrame()\n",
    "    df_gyro = pd.DataFrame()\n",
    "    df_gyro_uncali = pd.DataFrame()\n",
    "    df_magn = pd.DataFrame()\n",
    "    df_magn_uncali = pd.DataFrame()\n",
    "    df_ahrs = pd.DataFrame()\n",
    "    df_wifi = pd.DataFrame()\n",
    "    df_ibeacon = pd.DataFrame()\n",
    "    df_waypoint = pd.DataFrame()\n",
    "\n",
    "    for site in site_split[:]:\n",
    "        site_id = dic_site_[site]    \n",
    "        for floor in os.listdir(os.path.join('train', site))[:]:\n",
    "            floor_id = dic_floor_[floor]\n",
    "#             print(site, floor)\n",
    "            for file_nm in os.listdir(os.path.join('train', site, floor))[:]:\n",
    "                unique_id = dic_unique_[file_nm]            \n",
    "                print(site, floor, file_nm)\n",
    "                file_path = os.path.join('train', site, floor, file_nm)\n",
    "\n",
    "                rd = read_data_file(file_path)\n",
    "                start_time = rd.info[0]\n",
    "\n",
    "                df_acce = df_acce.append(get_sensor_df(rd.acce, start_time, site_id, floor_id, unique_id))\n",
    "                df_acce_uncali = df_acce_uncali.append(get_sensor_df(rd.acce_uncali, start_time, site_id, floor_id, unique_id))\n",
    "                df_gyro = df_gyro.append(get_sensor_df(rd.gyro, start_time, site_id, floor_id, unique_id))\n",
    "                df_gyro_uncali = df_gyro_uncali.append(get_sensor_df(rd.gyro_uncali, start_time, site_id, floor_id, unique_id))\n",
    "                df_magn = df_magn.append(get_sensor_df(rd.magn, start_time, site_id, floor_id, unique_id))\n",
    "                df_magn_uncali = df_magn_uncali.append(get_sensor_df(rd.magn_uncali, start_time, site_id, floor_id, unique_id))\n",
    "                df_ahrs = df_ahrs.append(get_sensor_df(rd.ahrs, start_time, site_id, floor_id, unique_id))\n",
    "                \n",
    "                df_tmp = get_sensor_df(rd.wifi, start_time, site_id, floor_id, unique_id)\n",
    "                if len(df_tmp) > 0 : df_tmp = df_tmp.astype({3:'float'})\n",
    "                df_wifi = df_wifi.append(df_tmp)\n",
    "                                               \n",
    "                df_tmp = get_sensor_df(rd.ibeacon, start_time, site_id, floor_id, unique_id)                                            \n",
    "                if len(df_tmp) > 0 : df_tmp = df_tmp.astype({2:'float'})\n",
    "                df_ibeacon = df_ibeacon.append(df_tmp)\n",
    "\n",
    "                df_waypoint = df_waypoint.append(get_sensor_df(rd.waypoint, start_time, site_id, floor_id, unique_id))\n",
    "\n",
    "    df_acce.to_pickle(\"data/df_acce_%s\"%(idx))\n",
    "    df_acce_uncali.to_pickle(\"data/df_acce_uncali_%s\"%(idx))\n",
    "    df_gyro.to_pickle(\"data/df_gyro_%s\"%(idx))\n",
    "    df_gyro_uncali.to_pickle(\"data/df_gyro_uncali_%s\"%(idx))    \n",
    "    df_magn.to_pickle(\"data/df_magn_%s\"%(idx))\n",
    "    df_magn_uncali.to_pickle(\"data/df_magn_uncali_%s\"%(idx))\n",
    "    df_ahrs.to_pickle(\"data/df_ahrs_%s\"%(idx))\n",
    "    \n",
    "    df_wifi.to_pickle(\"data/df_wifi_%s\"%(idx))\n",
    "    df_ibeacon.to_pickle(\"data/df_ibeacon_%s\"%(idx))\n",
    "    df_waypoint.to_pickle(\"data/df_waypoint_%s\"%(idx))\n",
    "    \n",
    "    del df_acce, df_acce_uncali, df_gyro, df_gyro_uncali, df_magn, df_magn_uncali, df_ahrs, df_wifi, df_ibeacon, df_waypoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/dic_site_.pkl', 'rb') as f:\n",
    "#     dic_site_ = pickle.load(f)\n",
    "\n",
    "# df_submit = pd.read_csv('sample_submission.csv')\n",
    "# df_submit[['site', 'path', 'timestamp']] = df_submit['site_path_timestamp'].apply(lambda x: pd.Series(x.split('_')))\n",
    "# df_submit['site_'] = df_submit.site.apply(lambda x: dic_site_[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 55s, sys: 34.2 s, total: 25min 29s\n",
      "Wall time: 25min 30s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# df = pd.read_pickle('data/df_wifi_v2.pkl')\n",
    "# df = df[df.site.isin(df_submit.site_.unique())]\n",
    "\n",
    "# df = df.rename(columns={'bssid_id':'bssid', 4:'lst'})\n",
    "# df = df.drop_duplicates(['uid', 'ts', 'bssid'])\n",
    "# df = df.sort_values(['uid', 'ts'])\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# df.lst = df.lst.astype('float64')\n",
    "\n",
    "# df['resp'] = df.apply(lambda x: 0 if (x.ts - x.lst) > 3500 else 1, axis=1)\n",
    "\n",
    "# df['rssi'] = df.rssi.astype(int) + 100\n",
    "# df['ts'] = (df.ts - 156e10)/1e10\n",
    "# df['lst'] = (df.lst - 156e10)/1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# max_n_bssid = 500\n",
    "# se_uid = df.groupby('uid').size()\n",
    "# start = 0\n",
    "# dic_data = {}\n",
    "# for uid, n in se_uid.items():\n",
    "#     dic_uid = {}\n",
    "#     df_uid = df.iloc[start:start+n]\n",
    "    \n",
    "#     df_uid['rssi_'] = df_uid.rssi * df_uid.resp\n",
    "#     l_bssid = df_uid.pivot('ts', 'bssid', 'rssi_').fillna(-1).mean().sort_values(ascending=False).index[:max_n_bssid].tolist() \n",
    "\n",
    "#     df_ = df_uid.pivot('ts', 'bssid', 'rssi').fillna(0).loc[:, l_bssid]\n",
    "#     dic_uid['time'] = df_.index.values\n",
    "#     dic_uid['bssid'] = df_.columns.values\n",
    "#     dic_uid['rssi'] = df_.values\n",
    "    \n",
    "#     dic_uid['lst'] = df_uid.pivot('ts', 'bssid', 'lst').fillna(0).loc[:, l_bssid].values\n",
    "#     dic_uid['resp'] = df_uid.pivot('ts', 'bssid', 'resp').fillna(0).loc[:, l_bssid].values\n",
    "        \n",
    "#     dic_data[uid] = dic_uid\n",
    "#     start += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 2.23 s, total: 2min 32s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# max_n_bssid = 500\n",
    "# se_uid = df.groupby('uid').size()\n",
    "# start = 0\n",
    "# dic_data = {}\n",
    "# for uid, n in se_uid.items():\n",
    "#     df_uid = df.iloc[start:start+n]\n",
    "    \n",
    "#     dic_uid = {}\n",
    "#     dic_uid['bssid'] = np.empty([0, max_n_bssid], dtype=np.int64)\n",
    "#     dic_uid['rssi'] = np.empty([0, max_n_bssid], dtype=np.int64)\n",
    "#     dic_uid['time'] = np.empty(0, dtype=np.float64)  \n",
    "#     dic_uid['lst'] = np.empty([0, max_n_bssid], dtype=np.float64)  \n",
    "#     dic_uid['resp'] = np.empty([0, max_n_bssid], dtype=np.int64)  \n",
    "    \n",
    "#     se_time = df_uid.groupby('ts').size()\n",
    "#     start_t = 0\n",
    "#     for time, m in se_time.items():\n",
    "#         df_uid_time = df_uid.iloc[start_t:start_t+m].iloc[:max_n_bssid]\n",
    "        \n",
    "#         val = df_uid_time.bssid.values\n",
    "#         ar = np.zeros((1, max_n_bssid), dtype=np.int64)\n",
    "#         ar[0, :len(val)] = val\n",
    "#         dic_uid['bssid'] = np.concatenate((dic_uid['bssid'], ar), axis=0)\n",
    "\n",
    "#         val = df_uid_time.rssi.values\n",
    "#         ar = np.zeros((1, max_n_bssid), dtype=np.int64)\n",
    "#         ar[0, :len(val)] = val\n",
    "#         dic_uid['rssi'] = np.concatenate((dic_uid['rssi'], ar), axis=0)\n",
    "\n",
    "#         dic_uid['time'] = np.concatenate([dic_uid['time'], df_uid_time.ts[0:1].values])\n",
    "        \n",
    "#         val = df_uid_time.lst.values\n",
    "#         ar = np.zeros((1, max_n_bssid), dtype=np.float64)\n",
    "#         ar[0, :len(val)] = val        \n",
    "#         dic_uid['lst'] = np.concatenate((dic_uid['lst'], ar), axis=0)\n",
    "                                         \n",
    "#         val = df_uid_time.resp.values\n",
    "#         ar = np.zeros((1, max_n_bssid), dtype=np.int64)\n",
    "#         ar[0, :len(val)] = val        \n",
    "#         dic_uid['resp'] = np.concatenate((dic_uid['resp'], ar), axis=0)\n",
    "        \n",
    "#         start_t += m\n",
    "        \n",
    "#     dic_data[uid] = dic_uid\n",
    "#     start += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 s, sys: 2.02 s, total: 22.5 s\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# df_waypoint = pd.DataFrame()\n",
    "# for i in range(10):\n",
    "#     df_ = pd.read_pickle('data_/df_waypoint_' + str(i)).astype('float64')\n",
    "#     df_waypoint = pd.concat([df_waypoint, df_])\n",
    "    \n",
    "# df_waypoint.ts = (df_waypoint.ts - 156e10)/1e10\n",
    "# df_waypoint.floor = df_waypoint.floor\n",
    "\n",
    "# keys = dic_data.keys()\n",
    "# for uid in df_waypoint.uid.unique():\n",
    "#     if uid in keys:\n",
    "#         df_uid = df_waypoint[df_waypoint.uid == uid]\n",
    "#         dic_data[uid]['y'] = df_uid.loc[:, ['ts', 'floor', 1, 2]].values\n",
    "#         dic_data[uid]['site'] = df_uid.iloc[0].site\n",
    "#         dic_data[uid]['floor'] = df_uid.iloc[0].floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_acce = pd.DataFrame()\n",
    "# for idx in range(10):\n",
    "#     df_acce = df_acce.append(pd.read_pickle(\"data_/df_acce_%d\"%(idx)))\n",
    "# df_ahrs = pd.DataFrame()\n",
    "# for idx in range(10):\n",
    "#     df_ahrs = df_ahrs.append(pd.read_pickle(\"data_/df_ahrs_%d\"%(idx)))    \n",
    "    \n",
    "# df_gyro = pd.DataFrame()\n",
    "# for idx in range(10):\n",
    "#     df_gyro = df_gyro.append(pd.read_pickle(\"data_/df_gyro_%d\"%(idx)))        \n",
    "    \n",
    "# df_magn = pd.DataFrame()\n",
    "# for idx in range(10):\n",
    "#     df_magn = df_magn.append(pd.read_pickle(\"data_/df_magn_%d\"%(idx)))     \n",
    "    \n",
    "    \n",
    "# df_acce = df_acce.rename(columns={1:'ac_x', 2:'ac_y', 3:'ac_z'})\n",
    "# df_ahrs = df_ahrs.rename(columns={1:'ah_x', 2:'ah_y', 3:'ah_z'})\n",
    "# df_gyro = df_gyro.rename(columns={1:'gr_x', 2:'gr_y', 3:'gr_z'})\n",
    "# df_magn = df_magn.rename(columns={1:'mg_x', 2:'mg_y', 3:'mg_z'})\n",
    "\n",
    "# df_sensor = df_acce.merge(df_ahrs[['ah_x', 'ah_y', 'ah_z', 'ts', 'uid']], on=['ts', 'uid'])\\\n",
    "#             .merge(df_gyro[['gr_x', 'gr_y', 'gr_z', 'ts', 'uid']], on=['ts', 'uid']).merge(df_magn[['mg_x', 'mg_y', 'mg_z', 'ts', 'uid']], on=['ts', 'uid'])\n",
    "# # df_sensor.ts = (df_sensor.ts - 156e10)/1e10\n",
    "\n",
    "# cols = ['ts', 'ac_x', 'ac_y', 'ac_z', 'ah_x', 'ah_y', 'ah_z', 'gr_x', 'gr_y', 'gr_z', 'mg_x', 'mg_y', 'mg_z']\n",
    "# keys = dic_data.keys()\n",
    "# for uid in dic_data.keys():\n",
    "#     df_uid = df_sensor[df_sensor.uid == uid]\n",
    "#     df_uid = df_uid.set_index(pd.to_datetime(df_uid.ts * 1000000)).resample('200ms').mean()\n",
    "#     df_uid.ts = (df_uid.ts - 156e10)/1e10\n",
    "#     dic_data[uid]['sensor'] = df_uid.loc[:, cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dic_data_v1.pickle', 'wb') as f:\n",
    "#     pickle.dump(dic_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dic_data_v1.pickle', 'rb') as f:\n",
    "    dic_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_se(ar, tar, len_seq):\n",
    "    len_ar = len(ar)\n",
    "    try:\n",
    "        before_tar = np.where(ar < tar)[0][-1]\n",
    "    except:\n",
    "        before_tar = 0 \n",
    "        \n",
    "    if len_seq == 2:\n",
    "        if len_ar == 1:\n",
    "            return before_tar, before_tar+1\n",
    "        else:\n",
    "            return before_tar, before_tar+2\n",
    "\n",
    "    if before_tar < len_ar/2:\n",
    "        s = max(0, before_tar-math.ceil(len_seq/2)+1)\n",
    "        e = min(s+len_seq, len_ar)\n",
    "    else:\n",
    "        e = min(before_tar+len_seq//2+1, len_ar)\n",
    "        s = max(0, e-len_seq)     \n",
    "        \n",
    "    return s, e\n",
    "\n",
    "\n",
    "def get_se_1(ar, s_time, e_time):\n",
    "    len_ar = len(ar)\n",
    "    try:\n",
    "        s = np.where(ar >= s_time)[0][0]\n",
    "    except:\n",
    "        s = len_ar\n",
    "        \n",
    "    try:\n",
    "        e = np.where(ar <= e_time)[0][-1] + 1\n",
    "    except:\n",
    "        e = 0          \n",
    "        \n",
    "    return s, e\n",
    "\n",
    "# import math\n",
    "# for uid, dic_uid in dic_data.items():\n",
    "#     l_idx, l_idx_sub = [], []\n",
    "# #     len_time = len(dic_uid['time'])\n",
    "#     len_time = int((dic_uid['y'][-1, 0] - dic_uid['y'][0, 0])/1e-7) + 2\n",
    "\n",
    "#     t_int = np.linspace(dic_uid['y'][0, 0], dic_uid['y'][-1, 0], len_time)\n",
    "#     y_int = np.zeros([len_time, 4])\n",
    "#     y_int[:, 0] = t_int\n",
    "#     y_int[:, 1] = dic_uid['y'][0, 1]\n",
    "#     y_int[:, 2] = np.interp(t_int, dic_uid['y'][:, 0], dic_uid['y'][:, 2])\n",
    "#     y_int[:, 3] = np.interp(t_int, dic_uid['y'][:, 0], dic_uid['y'][:, 3])    \n",
    "#     dic_uid['y_int'] = y_int    \n",
    "\n",
    "#     for s_tar in range(len(t_int)-1):\n",
    "#         if len(t_int) == 1:\n",
    "#             e_tar = s_tar + 1\n",
    "#         else:\n",
    "#             e_tar = s_tar + 2\n",
    "#         s_time_tar, e_time_tar = t_int[s_tar], t_int[e_tar-1]\n",
    "#         s_wifi, e_wifi = get_se(dic_uid['time'], e_time_tar, CFG.n_time)\n",
    "#         s_sensor, e_sensor = get_se_1(dic_uid['sensor'][:, 0], s_time_tar, e_time_tar)\n",
    "#         l_idx.append((uid, s_tar, s_wifi, e_wifi, s_sensor, e_sensor, s_tar, e_tar))\n",
    "\n",
    "#     for tar, time_tar in enumerate(dic_uid['y'][:, 0]):\n",
    "#         s_wifi, e_wifi = get_se(dic_uid['time'], time_tar, CFG.n_time)\n",
    "#         s_tar, e_tar = get_se(t_int, time_tar, 2)\n",
    "#         s_time_tar, e_time_tar = t_int[s_tar], t_int[e_tar-1]\n",
    "#         s_sensor, e_sensor = get_se_1(dic_uid['sensor'][:, 0], s_time_tar, e_time_tar)\n",
    "#         l_idx_sub.append((uid, tar, s_wifi, e_wifi, s_sensor, e_sensor, s_tar, e_tar))\n",
    "\n",
    "# #         if len(dic_uid['ibeacon']) == 0:\n",
    "# #             b_start, b_end == 0\n",
    "# #         else:\n",
    "# #             arg_nearest = np.abs(time_tar - dic_uid['ibeacon'][:, 0]).argmin()\n",
    "# #             if arg_nearest < len_ibeacon_seq / 2:\n",
    "# #                 b_start = max(0, arg_nearest-CFG.ibeacon_seq_len//2)\n",
    "# #                 b_end = min(b_start+CFG.ibeacon_seq_len, len_ibeacon_seq)\n",
    "# #             else:\n",
    "# #                 b_end = min(arg_nearest+math.ceil(CFG.ibeacon_seq_len/2), len_ibeacon_seq)\n",
    "# #                 b_start = max(0, b_end-CFG.ibeacon_seq_len)\n",
    "            \n",
    "#     dic_uid['l_idx'] = l_idx\n",
    "#     dic_uid['l_idx_sub'] = l_idx_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.81 s, sys: 9.04 ms, total: 5.82 s\n",
      "Wall time: 5.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import math\n",
    "for uid, dic_uid in dic_data.items():\n",
    "    l_idx, l_idx_sub = [], []\n",
    "    len_time = len(dic_uid['time'])\n",
    "#     len_time = int((dic_uid['y'][-1, 0] - dic_uid['y'][0, 0])/1e-7) + 2\n",
    "\n",
    "    t_int = np.linspace(dic_uid['y'][0, 0], dic_uid['y'][-1, 0], len_time)\n",
    "    y_int = np.zeros([len_time, 4])\n",
    "    y_int[:, 0] = t_int\n",
    "    y_int[:, 1] = dic_uid['y'][0, 1]\n",
    "    y_int[:, 2] = np.interp(t_int, dic_uid['y'][:, 0], dic_uid['y'][:, 2])\n",
    "    y_int[:, 3] = np.interp(t_int, dic_uid['y'][:, 0], dic_uid['y'][:, 3])    \n",
    "    dic_uid['y_int'] = y_int    \n",
    "\n",
    "    for tar, time_tar in enumerate(dic_uid['y_int'][:, 0]):\n",
    "        time_tar = t_int[tar]\n",
    "        s_wifi, e_wifi = get_se(dic_uid['time'], time_tar, CFG.n_time)\n",
    "        l_idx.append((uid, tar, s_wifi, e_wifi))\n",
    "\n",
    "    for tar, time_tar in enumerate(dic_uid['y'][:, 0]):\n",
    "        s_wifi, e_wifi = get_se(dic_uid['time'], time_tar, CFG.n_time)\n",
    "        l_idx_sub.append((uid, tar, s_wifi, e_wifi))\n",
    "            \n",
    "    dic_uid['l_idx'] = l_idx\n",
    "    dic_uid['l_idx_sub'] = l_idx_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bssid': array([[13165, 61677, 62264, ...,     0,     0,     0],\n",
       "        [62264,  4290, 61677, ...,     0,     0,     0],\n",
       "        [61677, 62264, 50032, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [26388, 13165, 61677, ...,     0,     0,     0],\n",
       "        [26388, 13165, 61677, ...,     0,     0,     0],\n",
       "        [26388, 60708, 46852, ...,     0,     0,     0]]),\n",
       " 'rssi': array([[54, 51, 51, ...,  0,  0,  0],\n",
       "        [54, 54, 53, ...,  0,  0,  0],\n",
       "        [50, 50, 50, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [48, 47, 44, ...,  0,  0,  0],\n",
       "        [49, 47, 41, ...,  0,  0,  0],\n",
       "        [46, 42, 41, ...,  0,  0,  0]]),\n",
       " 'time': array([1.84626188, 1.84626207, 1.84626226, 1.84626246, 1.84626265,\n",
       "        1.84626284, 1.84626304, 1.84626323, 1.84626342, 1.84626362,\n",
       "        1.84626381, 1.84626401, 1.8462642 , 1.84626439, 1.84626459,\n",
       "        1.84626478, 1.84626498, 1.84626518]),\n",
       " 'lst': array([[1.84626033, 1.84626183, 1.84626183, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626202, 1.84626202, 1.84626202, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626221, 1.84626221, 1.84626221, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [1.84626463, 1.84626376, 1.84626472, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626482, 1.84626376, 1.84626492, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626502, 1.84626512, 1.84626498, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " 'resp': array([[0, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]]),\n",
       " 'y': array([[  1.84626184,   1.        , 230.03738   , 153.49635   ],\n",
       "        [  1.84626285,   1.        , 231.4029    , 158.41515   ],\n",
       "        [  1.84626389,   1.        , 232.462     , 164.41673   ],\n",
       "        [  1.84626497,   1.        , 233.94418   , 171.41417   ]]),\n",
       " 'site': 1.0,\n",
       " 'floor': 1.0,\n",
       " 'sensor': array([[ 1.84626187e+00, -3.79543309e-02,  4.56011013e+00, ...,\n",
       "         -1.28702161e+01,  1.05665211e+01, -3.03895952e+01],\n",
       "        [ 1.84626189e+00, -1.03668201e-02,  4.44735868e+00, ...,\n",
       "         -1.24191281e+01,  1.04447941e+01, -3.08453372e+01],\n",
       "        [ 1.84626191e+00, -1.75476073e-02,  4.43628384e+00, ...,\n",
       "         -1.22111508e+01,  1.11390689e+01, -3.00350954e+01],\n",
       "        ...,\n",
       "        [ 1.84626515e+00, -1.12427216e+00,  3.17262876e+00, ...,\n",
       "         -1.08236695e+01,  3.01475525e+01, -3.91479489e+01],\n",
       "        [ 1.84626517e+00,  1.12759404e-01,  1.33968658e+00, ...,\n",
       "         -1.09623718e+01,  2.63317868e+01, -4.16450500e+01],\n",
       "        [ 1.84626518e+00, -1.22488786e+00,  2.93437577e+00, ...,\n",
       "         -1.16561887e+01,  2.71293638e+01, -4.12742600e+01]]),\n",
       " 'ibeacon': array([[ 1.84626187,  1.        , 52.        ],\n",
       "        [ 1.84626188,  1.        , 35.        ],\n",
       "        [ 1.84626188,  1.        , 34.        ],\n",
       "        ...,\n",
       "        [ 1.84626513,  1.        , 37.        ],\n",
       "        [ 1.84626514,  1.        , 31.        ],\n",
       "        [ 1.84626514,  2.        , 31.        ]]),\n",
       " 'y_int': array([[  1.84626184,   1.        , 230.03738   , 153.49635   ],\n",
       "        [  1.84626202,   1.        , 230.28556112, 154.39033418],\n",
       "        [  1.84626221,   1.        , 230.53374223, 155.28431836],\n",
       "        [  1.84626239,   1.        , 230.78192335, 156.17830254],\n",
       "        [  1.84626257,   1.        , 231.03010447, 157.07228672],\n",
       "        [  1.84626276,   1.        , 231.27828558, 157.9662709 ],\n",
       "        [  1.84626294,   1.        , 231.49584551, 158.94184239],\n",
       "        [  1.84626313,   1.        , 231.68252461, 159.99969297],\n",
       "        [  1.84626331,   1.        , 231.86920371, 161.05754355],\n",
       "        [  1.84626349,   1.        , 232.05588281, 162.11539413],\n",
       "        [  1.84626368,   1.        , 232.24256191, 163.17324471],\n",
       "        [  1.84626386,   1.        , 232.42924101, 164.23109529],\n",
       "        [  1.84626405,   1.        , 232.671817  , 165.40728573],\n",
       "        [  1.84626423,   1.        , 232.9262896 , 166.60866259],\n",
       "        [  1.84626441,   1.        , 233.1807622 , 167.81003944],\n",
       "        [  1.8462646 ,   1.        , 233.4352348 , 169.01141629],\n",
       "        [  1.84626478,   1.        , 233.6897074 , 170.21279315],\n",
       "        [  1.84626497,   1.        , 233.94418   , 171.41417   ]]),\n",
       " 'l_idx': [(1, 0, 0, 3),\n",
       "  (1, 1, 0, 3),\n",
       "  (1, 2, 0, 3),\n",
       "  (1, 3, 1, 4),\n",
       "  (1, 4, 2, 5),\n",
       "  (1, 5, 3, 6),\n",
       "  (1, 6, 4, 7),\n",
       "  (1, 7, 5, 8),\n",
       "  (1, 8, 6, 9),\n",
       "  (1, 9, 7, 10),\n",
       "  (1, 10, 8, 11),\n",
       "  (1, 11, 9, 12),\n",
       "  (1, 12, 10, 13),\n",
       "  (1, 13, 11, 14),\n",
       "  (1, 14, 12, 15),\n",
       "  (1, 15, 13, 16),\n",
       "  (1, 16, 13, 16),\n",
       "  (1, 17, 14, 17)],\n",
       " 'l_idx_sub': [(1, 0, 0, 3), (1, 1, 4, 7), (1, 2, 9, 12), (1, 3, 14, 17)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# max_ = 0\n",
    "# for uid, dic_uid in dic_data.items():\n",
    "#     l_idx = []\n",
    "#     l_time = dic_uid['time']\n",
    "#     l_y_time = dic_uid['y'][:, 0]\n",
    "\n",
    "#     for i in range(len(l_time)):\n",
    "#         s, e = i, min(i+CFG.n_time, len(l_time))\n",
    "\n",
    "#         if s == 0:\n",
    "#             s_tar = 0\n",
    "#         else:\n",
    "#             for j in range(len(l_y_time)):\n",
    "#                 if l_y_time[j] > l_time[s] - 1e-6: # max: 4.33e-6\n",
    "#                     break\n",
    "#             s_tar = j\n",
    "        \n",
    "#         if e == len(l_time):\n",
    "#             e_tar = len(l_y_time)\n",
    "#         else:\n",
    "#             for j in range(len(l_y_time), 0, -1):\n",
    "#                 if l_y_time[j-1] < l_time[e-1] + 1e-6:\n",
    "#                     break \n",
    "#             e_tar = j\n",
    "\n",
    "#         l_idx.append((uid, s, e, s_tar, e_tar))\n",
    "#         # e_tar-s_tar: max 26개 (n_time=3 경우는 13)\n",
    "\n",
    "#         if e == len(l_time):\n",
    "#             break\n",
    "            \n",
    "#     dic_uid['l_idx'] = l_idx\n",
    "# #     dic_uid['l_idx_sub'] = l_idx            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import math\n",
    "# for uid, dic_uid in dic_data.items():\n",
    "#     l_idx_sub = []\n",
    "#     len_time = len(dic_uid['time'])\n",
    "    \n",
    "#     for tar, time_tar in enumerate(dic_uid['y'][:, 0]):\n",
    "#         arg_nearest = np.abs(time_tar - dic_uid['time']).argmin()\n",
    "        \n",
    "#         if arg_nearest < len_time / 2:\n",
    "#             s = max(0, arg_nearest-CFG.n_time//2)\n",
    "#             e = min(s+CFG.n_time, len_time)\n",
    "#         else:\n",
    "#             e = min(arg_nearest+math.ceil(CFG.n_time/2), len_time)\n",
    "#             s = max(0, e-CFG.n_time)\n",
    "\n",
    "#         l_idx_sub.append((uid, s, e, tar, tar+1))\n",
    "\n",
    "#     dic_uid['l_idx_sub'] = l_idx_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# l_idx = []\n",
    "# for uid in dic_data.keys():\n",
    "#     l_idx += dic_data[uid]['l_idx']\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# l_idx_train, l_idx_valid = train_test_split(l_idx, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_uid = np.array(list(dic_data.keys()))\n",
    "l_site = []\n",
    "for uid in ar_uid:\n",
    "    l_site.append(dic_data[uid]['site'])\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stk = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "for idx_uid_train, idx_uid_valid in stk.split(ar_uid, l_site):\n",
    "    break\n",
    "\n",
    "l_idx_train, l_idx_valid = [], []\n",
    "\n",
    "for uid in ar_uid[idx_uid_train]:\n",
    "    l_idx_train += dic_data[uid]['l_idx']\n",
    "for uid in ar_uid[idx_uid_valid]:\n",
    "    l_idx_valid += dic_data[uid]['l_idx_sub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231652, 7568)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l_idx_train), len(l_idx_valid) # 이전 (67638, 7568)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0, 0, 3), (2, 1, 0, 3), (2, 2, 0, 3)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_idx_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(s, e, is_test):\n",
    "    if is_test:\n",
    "        N = CFG.n_bssid\n",
    "    else:\n",
    "        N = CFG.total_n_bssid\n",
    "        \n",
    "    l = []\n",
    "    for i in range(s, e):\n",
    "        for j in range(N):\n",
    "            l.append((i, j))\n",
    "            \n",
    "    if is_test:\n",
    "        ar = np.array(l)\n",
    "    else:          \n",
    "        ar = np.array(l)[np.random.choice(range(len(l)), (e-s)*CFG.n_bssid, replace=False)]\n",
    "    \n",
    "    return ar[:, 0], ar[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 11000\n",
    "\n",
    "class ILNDataset(Dataset):\n",
    "    def __init__(self, l_idx, test=False):\n",
    "        self.l_idx = l_idx\n",
    "        self.test = test\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        u, t, s, e = self.l_idx[idx]  \n",
    "        dic_ = dic_data[u]\n",
    "\n",
    "        bssid = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        rssi = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        resp = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        time = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        lst = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        d_time = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        d_lst = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "\n",
    "        if self.test:\n",
    "            y = dic_['y'][t]            \n",
    "            idx_bssid = range(CFG.n_bssid)\n",
    "        else:\n",
    "            y = dic_['y_int'][t]\n",
    "            idx_bssid = np.random.choice(range(CFG.total_n_bssid), CFG.n_bssid, replace=False)\n",
    "            \n",
    "        length = (e-s) * CFG.n_bssid\n",
    "        bssid[:length] = dic_['bssid'][s:e, idx_bssid].flatten()\n",
    "        rssi[:length] = dic_['rssi'][s:e, idx_bssid].flatten()\n",
    "        resp[:length] = dic_['resp'][s:e, idx_bssid].flatten()\n",
    "        time[:length] = dic_['time'][s:e].repeat(CFG.n_bssid)\n",
    "        lst[:length] = dic_['lst'][s:e, idx_bssid].flatten()\n",
    "        d_time[:length] = dic_['time'][s:e].repeat(CFG.n_bssid) - y[0]\n",
    "        d_lst[:length] = dic_['lst'][s:e, idx_bssid].flatten() - y[0]\n",
    "        \n",
    "        mask_t = np.expand_dims(bssid!=0, -2) * 1\n",
    "        mask_b = bssid==0\n",
    "#         subsequent_mask = np.triu(np.ones((CFG.n_time, CFG.n_time)), k=1).astype('uint8') == 0  \n",
    "       \n",
    "        return bssid.astype(np.int64), rssi.astype(np.int64), resp.astype(np.float64), time.astype(np.float64), lst.astype(np.float64), \\\n",
    "    d_time.astype(np.float64), d_lst.astype(np.float64), y.astype(np.float64), mask_b, mask_t\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.l_idx)\n",
    "    \n",
    "\n",
    "train_db = ILNDataset(l_idx_train)\n",
    "valid_db = ILNDataset(l_idx_valid, test=True)\n",
    "\n",
    "train_loader = DataLoader(train_db, batch_size=CFG.batch_size, num_workers=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_db, batch_size=CFG.batch_size, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 11000\n",
    "\n",
    "class ILNDataset(Dataset):\n",
    "    def __init__(self, l_idx, test=False):\n",
    "        self.l_idx = l_idx\n",
    "        self.test = test\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        u, t, s, e = self.l_idx[idx]  \n",
    "        dic_ = dic_data[u]\n",
    "\n",
    "        bssid = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        rssi = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        resp = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        time = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        lst = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        d_time = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "        d_lst = np.zeros([CFG.n_time * CFG.n_bssid])\n",
    "\n",
    "        if self.test:\n",
    "            y = dic_['y'][t]            \n",
    "            idx_bssid = range(CFG.n_bssid)\n",
    "            \n",
    "            length = (e-s) * CFG.n_bssid\n",
    "            bssid[:length] = dic_['bssid'][s:e, idx_bssid].flatten()\n",
    "            rssi[:length] = dic_['rssi'][s:e, idx_bssid].flatten()\n",
    "            resp[:length] = dic_['resp'][s:e, idx_bssid].flatten()\n",
    "            time[:length] = dic_['time'][s:e].repeat(CFG.n_bssid)\n",
    "            lst[:length] = dic_['lst'][s:e, idx_bssid].flatten()\n",
    "            d_time[:length] = dic_['time'][s:e].repeat(CFG.n_bssid) - y[0]\n",
    "            d_lst[:length] = dic_['lst'][s:e, idx_bssid].flatten() - y[0]    \n",
    "            \n",
    "        else:\n",
    "            y = dic_['y_int'][t]\n",
    "#             idx_bssid = np.random.choice(range(CFG.total_n_bssid), CFG.n_bssid, replace=False)\n",
    "            idx_time = np.random.choice(range(s, e), CFG.n_time * CFG.n_bssid, replace=True)\n",
    "            idx_bssid = np.random.choice(range(CFG.total_n_bssid), CFG.n_time * CFG.n_bssid, replace=True)\n",
    "            \n",
    "            bssid = dic_['bssid'][idx_time, idx_bssid]\n",
    "            rssi = dic_['rssi'][idx_time, idx_bssid]\n",
    "            resp = dic_['resp'][idx_time, idx_bssid]\n",
    "            time = dic_['time'][idx_time]\n",
    "            lst = dic_['lst'][idx_time, idx_bssid]\n",
    "            d_time = dic_['time'][idx_time] - y[0]\n",
    "            d_lst = dic_['lst'][idx_time, idx_bssid] - y[0]\n",
    "        \n",
    "        mask_t = np.expand_dims(bssid!=0, -2) * 1\n",
    "        mask_b = bssid==0\n",
    "#         subsequent_mask = np.triu(np.ones((CFG.n_time, CFG.n_time)), k=1).astype('uint8') == 0  \n",
    "       \n",
    "        return bssid.astype(np.int64), rssi.astype(np.int64), resp.astype(np.float64), time.astype(np.float64), lst.astype(np.float64), \\\n",
    "    d_time.astype(np.float64), d_lst.astype(np.float64), y.astype(np.float64), mask_b, mask_t\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.l_idx)\n",
    "    \n",
    "\n",
    "train_db = ILNDataset(l_idx_train)\n",
    "valid_db = ILNDataset(l_idx_valid, test=True)\n",
    "\n",
    "train_loader = DataLoader(train_db, batch_size=CFG.batch_size, num_workers=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_db, batch_size=CFG.batch_size, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0, 0, 3), (2, 1, 0, 3), (2, 2, 0, 3)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_idx_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bssid': array([[13165, 61677, 62264, ...,     0,     0,     0],\n",
       "        [62264,  4290, 61677, ...,     0,     0,     0],\n",
       "        [61677, 62264, 50032, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [26388, 13165, 61677, ...,     0,     0,     0],\n",
       "        [26388, 13165, 61677, ...,     0,     0,     0],\n",
       "        [26388, 60708, 46852, ...,     0,     0,     0]]),\n",
       " 'rssi': array([[54, 51, 51, ...,  0,  0,  0],\n",
       "        [54, 54, 53, ...,  0,  0,  0],\n",
       "        [50, 50, 50, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [48, 47, 44, ...,  0,  0,  0],\n",
       "        [49, 47, 41, ...,  0,  0,  0],\n",
       "        [46, 42, 41, ...,  0,  0,  0]]),\n",
       " 'time': array([1.84626188, 1.84626207, 1.84626226, 1.84626246, 1.84626265,\n",
       "        1.84626284, 1.84626304, 1.84626323, 1.84626342, 1.84626362,\n",
       "        1.84626381, 1.84626401, 1.8462642 , 1.84626439, 1.84626459,\n",
       "        1.84626478, 1.84626498, 1.84626518]),\n",
       " 'lst': array([[1.84626033, 1.84626183, 1.84626183, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626202, 1.84626202, 1.84626202, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626221, 1.84626221, 1.84626221, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [1.84626463, 1.84626376, 1.84626472, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626482, 1.84626376, 1.84626492, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626502, 1.84626512, 1.84626498, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " 'resp': array([[0, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]]),\n",
       " 'y': array([[  1.84626184,   1.        , 230.03738   , 153.49635   ],\n",
       "        [  1.84626285,   1.        , 231.4029    , 158.41515   ],\n",
       "        [  1.84626389,   1.        , 232.462     , 164.41673   ],\n",
       "        [  1.84626497,   1.        , 233.94418   , 171.41417   ]]),\n",
       " 'site': 1.0,\n",
       " 'floor': 1.0,\n",
       " 'sensor': array([[ 1.84626187e+00, -3.79543309e-02,  4.56011013e+00, ...,\n",
       "         -1.28702161e+01,  1.05665211e+01, -3.03895952e+01],\n",
       "        [ 1.84626189e+00, -1.03668201e-02,  4.44735868e+00, ...,\n",
       "         -1.24191281e+01,  1.04447941e+01, -3.08453372e+01],\n",
       "        [ 1.84626191e+00, -1.75476073e-02,  4.43628384e+00, ...,\n",
       "         -1.22111508e+01,  1.11390689e+01, -3.00350954e+01],\n",
       "        ...,\n",
       "        [ 1.84626515e+00, -1.12427216e+00,  3.17262876e+00, ...,\n",
       "         -1.08236695e+01,  3.01475525e+01, -3.91479489e+01],\n",
       "        [ 1.84626517e+00,  1.12759404e-01,  1.33968658e+00, ...,\n",
       "         -1.09623718e+01,  2.63317868e+01, -4.16450500e+01],\n",
       "        [ 1.84626518e+00, -1.22488786e+00,  2.93437577e+00, ...,\n",
       "         -1.16561887e+01,  2.71293638e+01, -4.12742600e+01]]),\n",
       " 'ibeacon': array([[ 1.84626187,  1.        , 52.        ],\n",
       "        [ 1.84626188,  1.        , 35.        ],\n",
       "        [ 1.84626188,  1.        , 34.        ],\n",
       "        ...,\n",
       "        [ 1.84626513,  1.        , 37.        ],\n",
       "        [ 1.84626514,  1.        , 31.        ],\n",
       "        [ 1.84626514,  2.        , 31.        ]]),\n",
       " 'y_int': array([[  1.84626184,   1.        , 230.03738   , 153.49635   ],\n",
       "        [  1.84626202,   1.        , 230.28556112, 154.39033418],\n",
       "        [  1.84626221,   1.        , 230.53374223, 155.28431836],\n",
       "        [  1.84626239,   1.        , 230.78192335, 156.17830254],\n",
       "        [  1.84626257,   1.        , 231.03010447, 157.07228672],\n",
       "        [  1.84626276,   1.        , 231.27828558, 157.9662709 ],\n",
       "        [  1.84626294,   1.        , 231.49584551, 158.94184239],\n",
       "        [  1.84626313,   1.        , 231.68252461, 159.99969297],\n",
       "        [  1.84626331,   1.        , 231.86920371, 161.05754355],\n",
       "        [  1.84626349,   1.        , 232.05588281, 162.11539413],\n",
       "        [  1.84626368,   1.        , 232.24256191, 163.17324471],\n",
       "        [  1.84626386,   1.        , 232.42924101, 164.23109529],\n",
       "        [  1.84626405,   1.        , 232.671817  , 165.40728573],\n",
       "        [  1.84626423,   1.        , 232.9262896 , 166.60866259],\n",
       "        [  1.84626441,   1.        , 233.1807622 , 167.81003944],\n",
       "        [  1.8462646 ,   1.        , 233.4352348 , 169.01141629],\n",
       "        [  1.84626478,   1.        , 233.6897074 , 170.21279315],\n",
       "        [  1.84626497,   1.        , 233.94418   , 171.41417   ]]),\n",
       " 'l_idx': [(1, 0, 0, 3),\n",
       "  (1, 1, 0, 3),\n",
       "  (1, 2, 0, 3),\n",
       "  (1, 3, 1, 4),\n",
       "  (1, 4, 2, 5),\n",
       "  (1, 5, 3, 6),\n",
       "  (1, 6, 4, 7),\n",
       "  (1, 7, 5, 8),\n",
       "  (1, 8, 6, 9),\n",
       "  (1, 9, 7, 10),\n",
       "  (1, 10, 8, 11),\n",
       "  (1, 11, 9, 12),\n",
       "  (1, 12, 10, 13),\n",
       "  (1, 13, 11, 14),\n",
       "  (1, 14, 12, 15),\n",
       "  (1, 15, 13, 16),\n",
       "  (1, 16, 13, 16),\n",
       "  (1, 17, 14, 17)],\n",
       " 'l_idx_sub': [(1, 0, 0, 3), (1, 1, 4, 7), (1, 2, 9, 12), (1, 3, 14, 17)]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0, 0, 3), (1, 1, 4, 7), (1, 2, 9, 12)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_idx_valid[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bssid': array([[29673, 55073, 41976, ...,     0,     0,     0],\n",
       "        [26388, 29673, 55073, ...,     0,     0,     0],\n",
       "        [57277, 62264,  4290, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [55073, 29673, 23928, ...,     0,     0,     0],\n",
       "        [23928, 46483, 14921, ...,     0,     0,     0],\n",
       "        [46483, 11371, 24444, ...,     0,     0,     0]]),\n",
       " 'rssi': array([[51, 50, 50, ...,  0,  0,  0],\n",
       "        [50, 49, 48, ...,  0,  0,  0],\n",
       "        [55, 47, 47, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [52, 51, 51, ...,  0,  0,  0],\n",
       "        [51, 51, 50, ...,  0,  0,  0],\n",
       "        [51, 49, 49, ...,  0,  0,  0]]),\n",
       " 'time': array([1.84639686, 1.84639705, 1.84639725, 1.84639744, 1.84639763,\n",
       "        1.84639783, 1.84639802, 1.84639822, 1.84639841, 1.84639861,\n",
       "        1.8463988 ]),\n",
       " 'lst': array([[1.84639674, 1.84639679, 1.84639679, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.8463969 , 1.84639693, 1.84639699, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84639712, 1.84639719, 1.84639719, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [1.84639834, 1.84639829, 1.84639834, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84639834, 1.8463977 , 1.84639848, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.8463977 , 1.84639872, 1.84639872, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " 'resp': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0]]),\n",
       " 'y': array([[  1.84639667,   1.        , 198.36833   , 163.52063   ],\n",
       "        [  1.84639747,   1.        , 204.5289    , 162.11609   ],\n",
       "        [  1.84639859,   1.        , 197.0507    , 158.34859   ]]),\n",
       " 'site': 1.0,\n",
       " 'floor': 1.0,\n",
       " 'sensor': array([[  1.84639669,  -1.04460145,   3.97923431, ...,  -5.3434754 ,\n",
       "         -31.7350772 , -13.9027405 ],\n",
       "        [  1.84639671,  -1.10404053,   3.7525009 , ...,  -4.99649051,\n",
       "         -31.3879398 , -15.2525329 ],\n",
       "        [  1.84639673,  -1.24661865,   3.49476776, ...,  -4.23339842,\n",
       "         -30.9025574 , -15.1850889 ],\n",
       "        ...,\n",
       "        [  1.84639889,  -0.56893005,   4.05937654, ...,  40.4440303 ,\n",
       "         -12.3100283 ,  -7.96264657],\n",
       "        [  1.84639891,  -1.71917267,   5.43364873, ...,  41.6236875 ,\n",
       "         -12.72628795,  -4.04785153],\n",
       "        [  1.84639892,  -1.74224343,   5.68436177, ...,  41.878255  ,\n",
       "         -12.24060083,  -2.40529377]]),\n",
       " 'ibeacon': array([[ 1.84639667,  1.        , 34.        ],\n",
       "        [ 1.84639668,  1.        , 25.        ],\n",
       "        [ 1.84639668,  1.        , 31.        ],\n",
       "        [ 1.84639668,  1.        , 34.        ],\n",
       "        [ 1.84639669,  1.        , 29.        ],\n",
       "        [ 1.8463967 ,  1.        , 15.        ],\n",
       "        [ 1.8463967 ,  1.        , 34.        ],\n",
       "        [ 1.8463967 ,  1.        , 34.        ],\n",
       "        [ 1.84639671,  1.        , 25.        ],\n",
       "        [ 1.84639671,  1.        , 17.        ],\n",
       "        [ 1.84639673,  1.        , 33.        ],\n",
       "        [ 1.84639674,  1.        , 28.        ],\n",
       "        [ 1.84639675,  1.        , 32.        ],\n",
       "        [ 1.84639678,  1.        , 34.        ],\n",
       "        [ 1.84639681,  1.        , 29.        ],\n",
       "        [ 1.84639682,  6.        , 12.        ],\n",
       "        [ 1.84639682,  1.        , 30.        ],\n",
       "        [ 1.84639683,  1.        , 26.        ],\n",
       "        [ 1.84639683,  1.        , 26.        ],\n",
       "        [ 1.84639683,  1.        , 27.        ],\n",
       "        [ 1.84639685,  1.        , 25.        ],\n",
       "        [ 1.84639688,  1.        , 33.        ],\n",
       "        [ 1.84639689,  1.        , 31.        ],\n",
       "        [ 1.8463969 ,  1.        , 20.        ],\n",
       "        [ 1.84639691,  1.        , 21.        ],\n",
       "        [ 1.84639691,  1.        , 23.        ],\n",
       "        [ 1.84639695,  1.        , 30.        ],\n",
       "        [ 1.84639698,  1.        , 24.        ],\n",
       "        [ 1.846397  ,  1.        , 30.        ],\n",
       "        [ 1.84639701,  1.        , 24.        ],\n",
       "        [ 1.84639702,  1.        , 24.        ],\n",
       "        [ 1.84639703,  1.        , 22.        ],\n",
       "        [ 1.84639703,  1.        , 19.        ],\n",
       "        [ 1.84639704,  1.        , 25.        ],\n",
       "        [ 1.84639705,  1.        , 20.        ],\n",
       "        [ 1.84639706,  1.        , 32.        ],\n",
       "        [ 1.84639706,  1.        , 22.        ],\n",
       "        [ 1.84639706,  1.        , 24.        ],\n",
       "        [ 1.84639706,  1.        , 32.        ],\n",
       "        [ 1.84639707,  1.        , 33.        ],\n",
       "        [ 1.84639708,  1.        , 22.        ],\n",
       "        [ 1.84639708,  1.        , 31.        ],\n",
       "        [ 1.84639708,  1.        , 23.        ],\n",
       "        [ 1.84639709,  1.        , 29.        ],\n",
       "        [ 1.84639709,  1.        , 18.        ],\n",
       "        [ 1.84639709,  1.        , 33.        ],\n",
       "        [ 1.8463971 ,  1.        , 21.        ],\n",
       "        [ 1.8463971 ,  1.        , 20.        ],\n",
       "        [ 1.84639712,  1.        , 24.        ],\n",
       "        [ 1.84639712,  1.        , 19.        ],\n",
       "        [ 1.84639712,  1.        , 25.        ],\n",
       "        [ 1.84639713,  1.        , 24.        ],\n",
       "        [ 1.84639713,  1.        , 28.        ],\n",
       "        [ 1.84639714,  1.        , 23.        ],\n",
       "        [ 1.84639714,  1.        , 27.        ],\n",
       "        [ 1.84639716,  1.        , 18.        ],\n",
       "        [ 1.84639716,  1.        , 24.        ],\n",
       "        [ 1.84639717,  1.        , 33.        ],\n",
       "        [ 1.84639717,  1.        , 27.        ],\n",
       "        [ 1.84639717,  1.        , 34.        ],\n",
       "        [ 1.84639717,  1.        , 26.        ],\n",
       "        [ 1.84639719,  1.        , 24.        ],\n",
       "        [ 1.8463972 ,  1.        , 20.        ],\n",
       "        [ 1.84639721,  1.        , 21.        ],\n",
       "        [ 1.84639721,  1.        , 30.        ],\n",
       "        [ 1.84639721,  1.        , 26.        ],\n",
       "        [ 1.84639722,  1.        , 30.        ],\n",
       "        [ 1.84639722,  1.        , 26.        ],\n",
       "        [ 1.84639723,  1.        , 32.        ],\n",
       "        [ 1.84639723,  1.        , 26.        ],\n",
       "        [ 1.84639723,  1.        , 32.        ],\n",
       "        [ 1.84639724,  1.        , 24.        ],\n",
       "        [ 1.84639724,  1.        , 28.        ],\n",
       "        [ 1.84639725,  1.        , 24.        ],\n",
       "        [ 1.84639725,  1.        , 21.        ],\n",
       "        [ 1.84639726,  1.        , 25.        ],\n",
       "        [ 1.84639726,  1.        , 23.        ],\n",
       "        [ 1.84639727,  1.        , 33.        ],\n",
       "        [ 1.84639727,  1.        , 32.        ],\n",
       "        [ 1.84639727,  1.        , 23.        ],\n",
       "        [ 1.84639729,  1.        , 32.        ],\n",
       "        [ 1.8463973 ,  1.        , 19.        ],\n",
       "        [ 1.84639731,  1.        , 19.        ],\n",
       "        [ 1.84639732,  1.        , 28.        ],\n",
       "        [ 1.84639734,  1.        , 28.        ],\n",
       "        [ 1.84639735,  1.        , 22.        ],\n",
       "        [ 1.84639735,  1.        , 29.        ],\n",
       "        [ 1.84639735,  1.        , 24.        ],\n",
       "        [ 1.84639736,  1.        , 24.        ],\n",
       "        [ 1.84639736,  1.        , 27.        ],\n",
       "        [ 1.84639736,  1.        , 23.        ],\n",
       "        [ 1.84639737,  1.        , 20.        ],\n",
       "        [ 1.84639738,  1.        , 22.        ],\n",
       "        [ 1.84639738,  1.        , 24.        ],\n",
       "        [ 1.84639739,  1.        , 35.        ],\n",
       "        [ 1.8463974 ,  1.        , 34.        ],\n",
       "        [ 1.8463974 ,  1.        , 24.        ],\n",
       "        [ 1.8463974 ,  1.        , 27.        ],\n",
       "        [ 1.84639741,  1.        , 32.        ],\n",
       "        [ 1.84639743,  1.        , 23.        ],\n",
       "        [ 1.8463975 ,  1.        , 25.        ],\n",
       "        [ 1.8463975 ,  1.        , 26.        ],\n",
       "        [ 1.84639751,  1.        , 21.        ],\n",
       "        [ 1.84639753,  1.        , 29.        ],\n",
       "        [ 1.84639753,  1.        , 21.        ],\n",
       "        [ 1.84639754,  1.        , 27.        ],\n",
       "        [ 1.84639754,  1.        , 27.        ],\n",
       "        [ 1.84639754,  1.        , 28.        ],\n",
       "        [ 1.84639755,  1.        , 33.        ],\n",
       "        [ 1.84639755,  1.        , 27.        ],\n",
       "        [ 1.84639755,  1.        , 25.        ],\n",
       "        [ 1.84639757,  1.        , 21.        ],\n",
       "        [ 1.84639757,  1.        , 30.        ],\n",
       "        [ 1.84639758,  1.        , 30.        ],\n",
       "        [ 1.8463976 ,  1.        , 38.        ],\n",
       "        [ 1.8463976 ,  1.        , 20.        ],\n",
       "        [ 1.84639761,  1.        , 23.        ],\n",
       "        [ 1.84639761,  1.        , 34.        ],\n",
       "        [ 1.84639761,  1.        , 27.        ],\n",
       "        [ 1.84639761,  1.        , 30.        ],\n",
       "        [ 1.84639762,  1.        , 34.        ],\n",
       "        [ 1.84639762,  1.        , 31.        ],\n",
       "        [ 1.84639763,  1.        , 43.        ],\n",
       "        [ 1.84639763,  1.        , 27.        ],\n",
       "        [ 1.84639764,  1.        , 38.        ],\n",
       "        [ 1.84639764,  1.        , 35.        ],\n",
       "        [ 1.84639764,  1.        , 33.        ],\n",
       "        [ 1.84639764,  1.        , 24.        ],\n",
       "        [ 1.84639765,  1.        , 30.        ],\n",
       "        [ 1.84639767,  1.        , 34.        ],\n",
       "        [ 1.84639767,  1.        , 31.        ],\n",
       "        [ 1.84639768,  1.        , 21.        ],\n",
       "        [ 1.84639768,  1.        , 29.        ],\n",
       "        [ 1.84639768,  1.        , 26.        ],\n",
       "        [ 1.84639769,  1.        , 26.        ],\n",
       "        [ 1.84639769,  1.        , 27.        ],\n",
       "        [ 1.84639769,  1.        , 25.        ],\n",
       "        [ 1.84639769,  1.        , 27.        ],\n",
       "        [ 1.8463977 ,  1.        , 26.        ],\n",
       "        [ 1.8463977 ,  1.        , 18.        ],\n",
       "        [ 1.84639771,  1.        , 24.        ],\n",
       "        [ 1.84639771,  1.        , 23.        ],\n",
       "        [ 1.84639772,  1.        , 30.        ],\n",
       "        [ 1.84639772,  1.        , 28.        ],\n",
       "        [ 1.84639772,  1.        , 16.        ],\n",
       "        [ 1.84639772,  1.        , 29.        ],\n",
       "        [ 1.84639773,  1.        , 17.        ],\n",
       "        [ 1.84639773,  1.        , 22.        ],\n",
       "        [ 1.84639773,  1.        , 29.        ],\n",
       "        [ 1.84639773,  1.        , 24.        ],\n",
       "        [ 1.84639774,  1.        , 30.        ],\n",
       "        [ 1.84639774,  1.        , 29.        ],\n",
       "        [ 1.84639774,  1.        , 16.        ],\n",
       "        [ 1.84639775,  1.        , 28.        ],\n",
       "        [ 1.84639775,  1.        , 27.        ],\n",
       "        [ 1.84639775,  1.        , 26.        ],\n",
       "        [ 1.84639775,  1.        , 28.        ],\n",
       "        [ 1.84639775,  1.        , 26.        ],\n",
       "        [ 1.84639775,  1.        , 26.        ],\n",
       "        [ 1.84639775,  1.        , 27.        ],\n",
       "        [ 1.84639776,  1.        , 23.        ],\n",
       "        [ 1.84639776,  1.        , 29.        ],\n",
       "        [ 1.84639776,  1.        , 29.        ],\n",
       "        [ 1.84639776,  1.        , 27.        ],\n",
       "        [ 1.84639776,  1.        , 22.        ],\n",
       "        [ 1.84639777,  1.        , 19.        ],\n",
       "        [ 1.84639777,  1.        , 28.        ],\n",
       "        [ 1.84639777,  1.        , 28.        ],\n",
       "        [ 1.84639778,  1.        , 29.        ],\n",
       "        [ 1.84639778,  1.        , 30.        ],\n",
       "        [ 1.84639778,  1.        , 27.        ],\n",
       "        [ 1.84639778,  1.        , 25.        ],\n",
       "        [ 1.84639778,  1.        , 20.        ],\n",
       "        [ 1.84639779,  1.        , 32.        ],\n",
       "        [ 1.84639779,  1.        , 24.        ],\n",
       "        [ 1.8463978 ,  1.        , 30.        ],\n",
       "        [ 1.8463978 ,  1.        , 27.        ],\n",
       "        [ 1.8463978 ,  1.        , 30.        ],\n",
       "        [ 1.84639781,  1.        , 34.        ],\n",
       "        [ 1.84639781,  1.        , 30.        ],\n",
       "        [ 1.84639782,  1.        , 30.        ],\n",
       "        [ 1.84639782,  1.        , 30.        ],\n",
       "        [ 1.84639783,  1.        , 32.        ],\n",
       "        [ 1.84639783,  1.        , 20.        ],\n",
       "        [ 1.84639783,  1.        , 29.        ],\n",
       "        [ 1.84639783,  1.        , 27.        ],\n",
       "        [ 1.84639783,  1.        , 28.        ],\n",
       "        [ 1.84639784,  1.        , 27.        ],\n",
       "        [ 1.84639785,  1.        , 32.        ],\n",
       "        [ 1.84639785,  1.        , 37.        ],\n",
       "        [ 1.84639785,  1.        , 24.        ],\n",
       "        [ 1.84639786,  1.        , 32.        ],\n",
       "        [ 1.84639786,  1.        , 33.        ],\n",
       "        [ 1.84639786,  1.        , 35.        ],\n",
       "        [ 1.84639787,  1.        , 30.        ],\n",
       "        [ 1.84639788,  1.        , 30.        ],\n",
       "        [ 1.84639788,  1.        , 31.        ],\n",
       "        [ 1.84639788,  1.        , 29.        ],\n",
       "        [ 1.84639789,  1.        , 30.        ],\n",
       "        [ 1.84639789,  1.        , 25.        ],\n",
       "        [ 1.8463979 ,  1.        , 28.        ],\n",
       "        [ 1.84639791,  1.        , 23.        ],\n",
       "        [ 1.84639791,  1.        , 24.        ],\n",
       "        [ 1.84639791,  1.        , 28.        ],\n",
       "        [ 1.84639791,  1.        , 23.        ],\n",
       "        [ 1.84639792,  1.        , 30.        ],\n",
       "        [ 1.84639792,  1.        , 22.        ],\n",
       "        [ 1.84639792,  1.        , 34.        ],\n",
       "        [ 1.84639792,  1.        , 23.        ],\n",
       "        [ 1.84639792,  1.        , 25.        ],\n",
       "        [ 1.84639792,  1.        , 26.        ],\n",
       "        [ 1.84639792,  1.        , 17.        ],\n",
       "        [ 1.84639793,  1.        , 32.        ],\n",
       "        [ 1.84639793,  1.        , 21.        ],\n",
       "        [ 1.84639793,  1.        , 30.        ],\n",
       "        [ 1.84639793,  1.        , 21.        ],\n",
       "        [ 1.84639794,  1.        , 28.        ],\n",
       "        [ 1.84639794,  1.        , 23.        ],\n",
       "        [ 1.84639795,  1.        , 32.        ],\n",
       "        [ 1.84639795,  1.        , 25.        ],\n",
       "        [ 1.84639796,  1.        , 29.        ],\n",
       "        [ 1.84639796,  1.        , 31.        ],\n",
       "        [ 1.84639796,  1.        , 22.        ],\n",
       "        [ 1.84639797,  1.        , 20.        ],\n",
       "        [ 1.84639797,  1.        , 16.        ],\n",
       "        [ 1.84639798,  1.        , 25.        ],\n",
       "        [ 1.84639798,  1.        , 28.        ],\n",
       "        [ 1.84639798,  1.        , 18.        ],\n",
       "        [ 1.84639799,  1.        , 24.        ],\n",
       "        [ 1.84639799,  1.        , 25.        ],\n",
       "        [ 1.846398  ,  1.        , 22.        ],\n",
       "        [ 1.846398  ,  1.        , 30.        ],\n",
       "        [ 1.846398  ,  1.        , 24.        ],\n",
       "        [ 1.84639801,  1.        , 18.        ],\n",
       "        [ 1.84639801,  1.        , 32.        ],\n",
       "        [ 1.84639801,  1.        , 23.        ],\n",
       "        [ 1.84639802,  1.        , 26.        ],\n",
       "        [ 1.84639802,  1.        , 29.        ],\n",
       "        [ 1.84639802,  1.        , 23.        ],\n",
       "        [ 1.84639802,  1.        , 25.        ],\n",
       "        [ 1.84639803,  1.        , 22.        ],\n",
       "        [ 1.84639809,  1.        , 26.        ],\n",
       "        [ 1.84639811,  1.        , 21.        ],\n",
       "        [ 1.84639817,  1.        , 23.        ],\n",
       "        [ 1.84639818,  1.        , 18.        ],\n",
       "        [ 1.84639825,  1.        , 23.        ],\n",
       "        [ 1.84639826,  1.        , 16.        ],\n",
       "        [ 1.84639826,  1.        , 17.        ],\n",
       "        [ 1.84639831,  1.        , 20.        ],\n",
       "        [ 1.84639837,  1.        , 19.        ],\n",
       "        [ 1.84639843,  5.        , 10.        ],\n",
       "        [ 1.84639845,  1.        , 18.        ],\n",
       "        [ 1.84639845,  1.        , 19.        ],\n",
       "        [ 1.84639847,  1.        , 20.        ],\n",
       "        [ 1.84639856,  1.        , 22.        ],\n",
       "        [ 1.84639857,  1.        , 20.        ],\n",
       "        [ 1.84639859,  1.        , 14.        ],\n",
       "        [ 1.8463987 ,  1.        , 25.        ],\n",
       "        [ 1.84639883,  1.        , 20.        ]]),\n",
       " 'y_int': array([[  1.84639667,   1.        , 198.36833   , 163.52063   ],\n",
       "        [  1.84639686,   1.        , 199.84020051, 163.18506024],\n",
       "        [  1.84639705,   1.        , 201.31207102, 162.84949048],\n",
       "        [  1.84639725,   1.        , 202.78394153, 162.51392071],\n",
       "        [  1.84639744,   1.        , 204.25581205, 162.17835095],\n",
       "        [  1.84639763,   1.        , 203.48138958, 161.58835665],\n",
       "        [  1.84639782,   1.        , 202.19525166, 160.94040332],\n",
       "        [  1.84639801,   1.        , 200.90911375, 160.29244999],\n",
       "        [  1.84639821,   1.        , 199.62297583, 159.64449666],\n",
       "        [  1.8463984 ,   1.        , 198.33683791, 158.99654333],\n",
       "        [  1.84639859,   1.        , 197.0507    , 158.34859   ]]),\n",
       " 'l_idx': [(2, 0, 0, 3),\n",
       "  (2, 1, 0, 3),\n",
       "  (2, 2, 0, 3),\n",
       "  (2, 3, 0, 3),\n",
       "  (2, 4, 1, 4),\n",
       "  (2, 5, 2, 5),\n",
       "  (2, 6, 3, 6),\n",
       "  (2, 7, 4, 7),\n",
       "  (2, 8, 5, 8),\n",
       "  (2, 9, 6, 9),\n",
       "  (2, 10, 7, 10)],\n",
       " 'l_idx_sub': [(2, 0, 0, 3), (2, 1, 2, 5), (2, 2, 7, 10)]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([60708, 56668, 24444, 53678, 11371, 18138, 55073, 64555, 45261,\n",
       "        60708, 60708, 17796, 35479,  4290, 44708, 11371, 45564, 21575,\n",
       "        56668,  2573, 49335, 45261, 61677, 23632, 60708, 41976, 18138,\n",
       "        45564, 15537,  2573, 60933, 14921,  8839, 15537, 53678, 24598,\n",
       "        44708, 50032, 50955,  8839, 43098, 23350, 43098,  3212, 30564,\n",
       "        46852, 35826,  4467, 37259, 23632, 49335, 45564, 35826, 34792,\n",
       "        62264, 11371, 45261, 61677,  8839, 53678, 17796, 48597, 14921,\n",
       "         8839, 31434,  9659, 60933, 60708,  3212, 29673, 55073, 14921,\n",
       "         3212, 30191, 24598, 25123, 37259, 26388, 48597, 55073, 64555,\n",
       "        43098, 31434, 44708, 55073, 56668, 61677, 15537,  4290, 60063,\n",
       "        23350, 24598, 15537, 41976, 17796,  4290, 61677, 52042, 57277,\n",
       "        35479, 46483, 45261,  3212, 23632, 43098, 41976, 30564, 13165,\n",
       "        44708,  2573, 11371, 24444, 63948, 18138, 10565, 23350,  1205,\n",
       "        56668, 46483, 50955]),\n",
       " array([37, 45, 37, 38, 34, 44, 50, 35, 31, 37, 41, 30, 34, 47, 31, 36, 33,\n",
       "        34, 45, 27, 36, 31, 38, 37, 46, 50, 45, 33, 30, 27, 41, 46, 39, 32,\n",
       "        38, 29, 31, 37, 32, 42, 30, 27, 35, 29, 38, 41, 36, 28, 27, 37, 38,\n",
       "        33, 36, 26, 38, 37, 30, 41, 42, 38, 29, 31, 46, 42, 27, 27, 41, 37,\n",
       "        26, 44, 48, 46, 29, 46, 34, 34, 27, 39, 31, 43, 36, 30, 27, 31, 43,\n",
       "        32, 41, 30, 37, 39, 37, 31, 30, 48, 29, 47, 41, 31, 55, 36, 45, 34,\n",
       "        29, 37, 35, 50, 38, 41, 31, 27, 34, 37, 27, 39, 37, 37, 36, 45, 44,\n",
       "        31]),\n",
       " array([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "        1.]),\n",
       " array([1.84639705, 1.84639686, 1.84639686, 1.84639705, 1.84639705,\n",
       "        1.84639686, 1.84639686, 1.84639705, 1.84639686, 1.84639705,\n",
       "        1.84639686, 1.84639725, 1.84639705, 1.84639725, 1.84639686,\n",
       "        1.84639725, 1.84639705, 1.84639725, 1.84639686, 1.84639686,\n",
       "        1.84639725, 1.84639686, 1.84639705, 1.84639725, 1.84639725,\n",
       "        1.84639686, 1.84639705, 1.84639705, 1.84639725, 1.84639686,\n",
       "        1.84639725, 1.84639705, 1.84639705, 1.84639705, 1.84639705,\n",
       "        1.84639725, 1.84639705, 1.84639705, 1.84639686, 1.84639686,\n",
       "        1.84639705, 1.84639686, 1.84639686, 1.84639705, 1.84639725,\n",
       "        1.84639705, 1.84639686, 1.84639725, 1.84639725, 1.84639705,\n",
       "        1.84639705, 1.84639705, 1.84639686, 1.84639686, 1.84639705,\n",
       "        1.84639686, 1.84639725, 1.84639686, 1.84639686, 1.84639705,\n",
       "        1.84639705, 1.84639725, 1.84639686, 1.84639686, 1.84639705,\n",
       "        1.84639725, 1.84639725, 1.84639705, 1.84639686, 1.84639725,\n",
       "        1.84639705, 1.84639725, 1.84639705, 1.84639686, 1.84639705,\n",
       "        1.84639705, 1.84639725, 1.84639686, 1.84639686, 1.84639725,\n",
       "        1.84639725, 1.84639705, 1.84639686, 1.84639725, 1.84639725,\n",
       "        1.84639725, 1.84639686, 1.84639686, 1.84639705, 1.84639705,\n",
       "        1.84639705, 1.84639686, 1.84639686, 1.84639705, 1.84639705,\n",
       "        1.84639725, 1.84639686, 1.84639705, 1.84639725, 1.84639725,\n",
       "        1.84639686, 1.84639705, 1.84639705, 1.84639686, 1.84639686,\n",
       "        1.84639686, 1.84639725, 1.84639686, 1.84639705, 1.84639686,\n",
       "        1.84639705, 1.84639686, 1.84639686, 1.84639725, 1.84639686,\n",
       "        1.84639705, 1.84639725, 1.84639686, 1.84639705, 1.84639705]),\n",
       " array([1.846397  , 1.84639526, 1.84639678, 1.84639689, 1.84639697,\n",
       "        1.84639668, 1.84639679, 1.84639697, 1.84639675, 1.846397  ,\n",
       "        1.84639681, 1.84639717, 1.84639697, 1.84639719, 1.84639524,\n",
       "        1.84639717, 1.84639696, 1.84639709, 1.84639526, 1.84639529,\n",
       "        1.84639709, 1.84639675, 1.846397  , 1.84639678, 1.84639719,\n",
       "        1.84639679, 1.84639687, 1.84639696, 1.84639714, 1.84639529,\n",
       "        1.84639718, 1.84639674, 1.84639687, 1.84639694, 1.84639689,\n",
       "        1.84639714, 1.84639524, 1.846397  , 1.84639675, 1.84639523,\n",
       "        1.84639689, 1.8463967 , 1.84639526, 1.84639698, 1.84639707,\n",
       "        1.84639687, 1.8463967 , 1.8463969 , 1.8463953 , 1.84639678,\n",
       "        1.84639689, 1.84639696, 1.8463967 , 1.84639679, 1.846397  ,\n",
       "        1.84639678, 1.84639714, 1.84639681, 1.84639523, 1.84639689,\n",
       "        1.84639698, 1.84639714, 1.84639674, 1.84639523, 1.84639413,\n",
       "        1.84639523, 1.84639718, 1.846397  , 1.84639679, 1.84639712,\n",
       "        1.84639699, 1.84639674, 1.84639698, 1.84639671, 1.84639694,\n",
       "        1.8463969 , 1.8463953 , 1.84639671, 1.84639675, 1.84639718,\n",
       "        1.84639717, 1.84639689, 1.84639413, 1.84639524, 1.84639718,\n",
       "        1.84639709, 1.84639681, 1.84639675, 1.846397  , 1.84639691,\n",
       "        1.84639689, 1.84639675, 1.84639675, 1.84639699, 1.84639698,\n",
       "        1.84639719, 1.84639681, 1.84639674, 1.84639712, 1.84639717,\n",
       "        1.84639673, 1.84639694, 1.84639698, 1.84639678, 1.84639526,\n",
       "        1.84639679, 1.84639707, 1.84639681, 1.84639524, 1.84639529,\n",
       "        1.84639697, 1.84639678, 1.84639471, 1.84639706, 1.84639525,\n",
       "        1.84639689, 1.84639717, 1.84639526, 1.84639693, 1.84639694]),\n",
       " array([3.853e-07, 1.919e-07, 1.919e-07, 3.853e-07, 3.853e-07, 1.919e-07,\n",
       "        1.919e-07, 3.853e-07, 1.919e-07, 3.853e-07, 1.919e-07, 5.781e-07,\n",
       "        3.853e-07, 5.781e-07, 1.919e-07, 5.781e-07, 3.853e-07, 5.781e-07,\n",
       "        1.919e-07, 1.919e-07, 5.781e-07, 1.919e-07, 3.853e-07, 5.781e-07,\n",
       "        5.781e-07, 1.919e-07, 3.853e-07, 3.853e-07, 5.781e-07, 1.919e-07,\n",
       "        5.781e-07, 3.853e-07, 3.853e-07, 3.853e-07, 3.853e-07, 5.781e-07,\n",
       "        3.853e-07, 3.853e-07, 1.919e-07, 1.919e-07, 3.853e-07, 1.919e-07,\n",
       "        1.919e-07, 3.853e-07, 5.781e-07, 3.853e-07, 1.919e-07, 5.781e-07,\n",
       "        5.781e-07, 3.853e-07, 3.853e-07, 3.853e-07, 1.919e-07, 1.919e-07,\n",
       "        3.853e-07, 1.919e-07, 5.781e-07, 1.919e-07, 1.919e-07, 3.853e-07,\n",
       "        3.853e-07, 5.781e-07, 1.919e-07, 1.919e-07, 3.853e-07, 5.781e-07,\n",
       "        5.781e-07, 3.853e-07, 1.919e-07, 5.781e-07, 3.853e-07, 5.781e-07,\n",
       "        3.853e-07, 1.919e-07, 3.853e-07, 3.853e-07, 5.781e-07, 1.919e-07,\n",
       "        1.919e-07, 5.781e-07, 5.781e-07, 3.853e-07, 1.919e-07, 5.781e-07,\n",
       "        5.781e-07, 5.781e-07, 1.919e-07, 1.919e-07, 3.853e-07, 3.853e-07,\n",
       "        3.853e-07, 1.919e-07, 1.919e-07, 3.853e-07, 3.853e-07, 5.781e-07,\n",
       "        1.919e-07, 3.853e-07, 5.781e-07, 5.781e-07, 1.919e-07, 3.853e-07,\n",
       "        3.853e-07, 1.919e-07, 1.919e-07, 1.919e-07, 5.781e-07, 1.919e-07,\n",
       "        3.853e-07, 1.919e-07, 3.853e-07, 1.919e-07, 1.919e-07, 5.781e-07,\n",
       "        1.919e-07, 3.853e-07, 5.781e-07, 1.919e-07, 3.853e-07, 3.853e-07]),\n",
       " array([ 3.29000000e-07, -1.41080000e-06,  1.12600000e-07,  2.22600000e-07,\n",
       "         3.04100000e-07,  6.60000010e-09,  1.24000000e-07,  3.04100000e-07,\n",
       "         8.22999999e-08,  3.29000000e-07,  1.37600000e-07,  5.04100000e-07,\n",
       "         3.04200000e-07,  5.22700000e-07, -1.43190000e-06,  4.97800000e-07,\n",
       "         2.91600000e-07,  4.21100000e-07, -1.41080000e-06, -1.37880000e-06,\n",
       "         4.19200000e-07,  8.22999999e-08,  3.28900000e-07,  1.12700000e-07,\n",
       "         5.22900000e-07,  1.21700000e-07,  2.01100000e-07,  2.91600000e-07,\n",
       "         4.68800000e-07, -1.37880000e-06,  5.10300000e-07,  6.92000000e-08,\n",
       "         2.00600000e-07,  2.75200000e-07,  2.22600000e-07,  4.68800000e-07,\n",
       "        -1.43190000e-06,  3.28800000e-07,  8.14000001e-08, -1.43930000e-06,\n",
       "         2.23600000e-07,  2.98000000e-08, -1.41290000e-06,  3.10500000e-07,\n",
       "         3.97600000e-07,  1.97800000e-07,  2.67000000e-08,  2.31600000e-07,\n",
       "        -1.36610000e-06,  1.12700000e-07,  2.22400000e-07,  2.91600000e-07,\n",
       "         2.67000000e-08,  1.19700000e-07,  3.28800000e-07,  1.12700000e-07,\n",
       "         4.69600000e-07,  1.37400000e-07, -1.43930000e-06,  2.22600000e-07,\n",
       "         3.10400000e-07,  4.69200000e-07,  6.92000000e-08, -1.43930000e-06,\n",
       "        -2.54110000e-06, -1.44140000e-06,  5.10300000e-07,  3.29000000e-07,\n",
       "         1.19800000e-07,  4.51900000e-07,  3.16400000e-07,  6.92000000e-08,\n",
       "         3.10500000e-07,  3.79000000e-08,  2.75200000e-07,  2.28500000e-07,\n",
       "        -1.36610000e-06,  3.82000001e-08,  8.21999999e-08,  5.10200000e-07,\n",
       "         4.97800000e-07,  2.23600000e-07, -2.54110000e-06, -1.43190000e-06,\n",
       "         5.10200000e-07,  4.24100000e-07,  1.37400000e-07,  7.85000001e-08,\n",
       "         3.28900000e-07,  2.42900000e-07,  2.22100000e-07,  8.22999999e-08,\n",
       "         7.85000001e-08,  3.16200000e-07,  3.10400000e-07,  5.22700000e-07,\n",
       "         1.37400000e-07,  6.97000000e-08,  4.55900000e-07,  4.97900000e-07,\n",
       "         6.55000001e-08,  2.75200000e-07,  3.10500000e-07,  1.12700000e-07,\n",
       "        -1.41290000e-06,  1.21700000e-07,  3.97600000e-07,  1.37500000e-07,\n",
       "        -1.43190000e-06, -1.37880000e-06,  3.04100000e-07,  1.12600000e-07,\n",
       "        -1.95680000e-06,  3.89100000e-07, -1.41660000e-06,  2.22100000e-07,\n",
       "         4.98000000e-07, -1.41080000e-06,  2.60000000e-07,  2.75100000e-07]),\n",
       " array([  1.84639667,   1.        , 198.36833   , 163.52063   ]),\n",
       " array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False]),\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_db[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bssid': array([[13165, 61677, 62264, ...,     0,     0,     0],\n",
       "        [62264,  4290, 61677, ...,     0,     0,     0],\n",
       "        [61677, 62264, 50032, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [26388, 13165, 61677, ...,     0,     0,     0],\n",
       "        [26388, 13165, 61677, ...,     0,     0,     0],\n",
       "        [26388, 60708, 46852, ...,     0,     0,     0]]),\n",
       " 'rssi': array([[54, 51, 51, ...,  0,  0,  0],\n",
       "        [54, 54, 53, ...,  0,  0,  0],\n",
       "        [50, 50, 50, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [48, 47, 44, ...,  0,  0,  0],\n",
       "        [49, 47, 41, ...,  0,  0,  0],\n",
       "        [46, 42, 41, ...,  0,  0,  0]]),\n",
       " 'time': array([1.84626188, 1.84626207, 1.84626226, 1.84626246, 1.84626265,\n",
       "        1.84626284, 1.84626304, 1.84626323, 1.84626342, 1.84626362,\n",
       "        1.84626381, 1.84626401, 1.8462642 , 1.84626439, 1.84626459,\n",
       "        1.84626478, 1.84626498, 1.84626518]),\n",
       " 'lst': array([[1.84626033, 1.84626183, 1.84626183, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626202, 1.84626202, 1.84626202, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626221, 1.84626221, 1.84626221, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [1.84626463, 1.84626376, 1.84626472, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626482, 1.84626376, 1.84626492, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.84626502, 1.84626512, 1.84626498, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " 'resp': array([[0, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]]),\n",
       " 'y': array([[  1.84626184,   1.        , 230.03738   , 153.49635   ],\n",
       "        [  1.84626285,   1.        , 231.4029    , 158.41515   ],\n",
       "        [  1.84626389,   1.        , 232.462     , 164.41673   ],\n",
       "        [  1.84626497,   1.        , 233.94418   , 171.41417   ]]),\n",
       " 'site': 1.0,\n",
       " 'floor': 1.0,\n",
       " 'sensor': array([[ 1.84626187e+00, -3.79543309e-02,  4.56011013e+00, ...,\n",
       "         -1.28702161e+01,  1.05665211e+01, -3.03895952e+01],\n",
       "        [ 1.84626189e+00, -1.03668201e-02,  4.44735868e+00, ...,\n",
       "         -1.24191281e+01,  1.04447941e+01, -3.08453372e+01],\n",
       "        [ 1.84626191e+00, -1.75476073e-02,  4.43628384e+00, ...,\n",
       "         -1.22111508e+01,  1.11390689e+01, -3.00350954e+01],\n",
       "        ...,\n",
       "        [ 1.84626515e+00, -1.12427216e+00,  3.17262876e+00, ...,\n",
       "         -1.08236695e+01,  3.01475525e+01, -3.91479489e+01],\n",
       "        [ 1.84626517e+00,  1.12759404e-01,  1.33968658e+00, ...,\n",
       "         -1.09623718e+01,  2.63317868e+01, -4.16450500e+01],\n",
       "        [ 1.84626518e+00, -1.22488786e+00,  2.93437577e+00, ...,\n",
       "         -1.16561887e+01,  2.71293638e+01, -4.12742600e+01]]),\n",
       " 'ibeacon': array([[ 1.84626187,  1.        , 52.        ],\n",
       "        [ 1.84626188,  1.        , 35.        ],\n",
       "        [ 1.84626188,  1.        , 34.        ],\n",
       "        ...,\n",
       "        [ 1.84626513,  1.        , 37.        ],\n",
       "        [ 1.84626514,  1.        , 31.        ],\n",
       "        [ 1.84626514,  2.        , 31.        ]]),\n",
       " 'y_int': array([[  1.84626184,   1.        , 230.03738   , 153.49635   ],\n",
       "        [  1.84626202,   1.        , 230.28556112, 154.39033418],\n",
       "        [  1.84626221,   1.        , 230.53374223, 155.28431836],\n",
       "        [  1.84626239,   1.        , 230.78192335, 156.17830254],\n",
       "        [  1.84626257,   1.        , 231.03010447, 157.07228672],\n",
       "        [  1.84626276,   1.        , 231.27828558, 157.9662709 ],\n",
       "        [  1.84626294,   1.        , 231.49584551, 158.94184239],\n",
       "        [  1.84626313,   1.        , 231.68252461, 159.99969297],\n",
       "        [  1.84626331,   1.        , 231.86920371, 161.05754355],\n",
       "        [  1.84626349,   1.        , 232.05588281, 162.11539413],\n",
       "        [  1.84626368,   1.        , 232.24256191, 163.17324471],\n",
       "        [  1.84626386,   1.        , 232.42924101, 164.23109529],\n",
       "        [  1.84626405,   1.        , 232.671817  , 165.40728573],\n",
       "        [  1.84626423,   1.        , 232.9262896 , 166.60866259],\n",
       "        [  1.84626441,   1.        , 233.1807622 , 167.81003944],\n",
       "        [  1.8462646 ,   1.        , 233.4352348 , 169.01141629],\n",
       "        [  1.84626478,   1.        , 233.6897074 , 170.21279315],\n",
       "        [  1.84626497,   1.        , 233.94418   , 171.41417   ]]),\n",
       " 'l_idx': [(1, 0, 0, 3),\n",
       "  (1, 1, 0, 3),\n",
       "  (1, 2, 0, 3),\n",
       "  (1, 3, 1, 4),\n",
       "  (1, 4, 2, 5),\n",
       "  (1, 5, 3, 6),\n",
       "  (1, 6, 4, 7),\n",
       "  (1, 7, 5, 8),\n",
       "  (1, 8, 6, 9),\n",
       "  (1, 9, 7, 10),\n",
       "  (1, 10, 8, 11),\n",
       "  (1, 11, 9, 12),\n",
       "  (1, 12, 10, 13),\n",
       "  (1, 13, 11, 14),\n",
       "  (1, 14, 12, 15),\n",
       "  (1, 15, 13, 16),\n",
       "  (1, 16, 13, 16),\n",
       "  (1, 17, 14, 17)],\n",
       " 'l_idx_sub': [(1, 0, 0, 3), (1, 1, 4, 7), (1, 2, 9, 12), (1, 3, 14, 17)]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([31434, 13165, 61677, 62264, 50032,  4290, 60708, 50955, 48597,\n",
       "        38797, 15537, 45261, 24598, 26388, 46852, 58829, 24517, 47574,\n",
       "        27478, 29617, 14921, 64859, 30564, 60063, 56668, 30191, 60326,\n",
       "          829, 52688, 41657, 49335, 23350, 29673, 12349, 12972, 58780,\n",
       "        52787, 37433, 39852, 55073, 15537, 48597, 45261, 24598, 31434,\n",
       "        50955, 61677, 62264, 50032,  4290, 60708, 13165, 38797, 26388,\n",
       "        58829, 46852, 64859, 60063, 29617, 30191, 57277, 30564, 14921,\n",
       "        24517, 56668, 35826, 60326, 55073, 23928,  8839, 52688, 41657,\n",
       "        29673, 47574, 53678, 12972, 58780, 54167, 52787, 37433, 50955,\n",
       "        45261, 15537, 24598, 31434, 48597, 61677, 62264, 50032,  4290,\n",
       "        60708, 38797, 13165, 26388, 58829, 46852, 64859, 30191, 57277,\n",
       "        14921, 30564, 60063, 39852, 56668, 60326, 55073, 23928, 27478,\n",
       "         8839, 41976, 29673, 24517, 41657, 35826, 58780, 52787, 47574,\n",
       "        37433, 54167, 12349]),\n",
       " array([52, 50, 48, 48, 48, 48, 48, 47, 47, 47, 46, 46, 46, 41, 37, 37, 35,\n",
       "        35, 34, 34, 34, 31, 31, 30, 29, 28, 28, 27, 27, 27, 27, 27, 26, 26,\n",
       "        26, 26, 25, 25, 25, 24, 51, 51, 51, 51, 50, 50, 49, 49, 49, 49, 48,\n",
       "        47, 47, 41, 37, 34, 34, 34, 34, 33, 32, 31, 31, 30, 29, 29, 28, 27,\n",
       "        27, 27, 27, 27, 26, 26, 26, 26, 26, 26, 25, 25, 53, 53, 52, 52, 51,\n",
       "        51, 48, 48, 48, 48, 47, 47, 46, 41, 37, 34, 34, 33, 32, 32, 31, 30,\n",
       "        30, 29, 28, 27, 27, 27, 27, 27, 26, 26, 26, 26, 26, 25, 25, 25, 25,\n",
       "        24]),\n",
       " array([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1.]),\n",
       " array([1.84626265, 1.84626265, 1.84626265, 1.84626265, 1.84626265,\n",
       "        1.84626265, 1.84626265, 1.84626265, 1.84626265, 1.84626265,\n",
       "        1.84626265, 1.84626265, 1.84626265, 1.84626265, 1.84626265,\n",
       "        1.84626265, 1.84626265, 1.84626265, 1.84626265, 1.84626265,\n",
       "        1.84626265, 1.84626265, 1.84626265, 1.84626265, 1.84626265,\n",
       "        1.84626265, 1.84626265, 1.84626265, 1.84626265, 1.84626265,\n",
       "        1.84626265, 1.84626265, 1.84626265, 1.84626265, 1.84626265,\n",
       "        1.84626265, 1.84626265, 1.84626265, 1.84626265, 1.84626265,\n",
       "        1.84626284, 1.84626284, 1.84626284, 1.84626284, 1.84626284,\n",
       "        1.84626284, 1.84626284, 1.84626284, 1.84626284, 1.84626284,\n",
       "        1.84626284, 1.84626284, 1.84626284, 1.84626284, 1.84626284,\n",
       "        1.84626284, 1.84626284, 1.84626284, 1.84626284, 1.84626284,\n",
       "        1.84626284, 1.84626284, 1.84626284, 1.84626284, 1.84626284,\n",
       "        1.84626284, 1.84626284, 1.84626284, 1.84626284, 1.84626284,\n",
       "        1.84626284, 1.84626284, 1.84626284, 1.84626284, 1.84626284,\n",
       "        1.84626284, 1.84626284, 1.84626284, 1.84626284, 1.84626284,\n",
       "        1.84626304, 1.84626304, 1.84626304, 1.84626304, 1.84626304,\n",
       "        1.84626304, 1.84626304, 1.84626304, 1.84626304, 1.84626304,\n",
       "        1.84626304, 1.84626304, 1.84626304, 1.84626304, 1.84626304,\n",
       "        1.84626304, 1.84626304, 1.84626304, 1.84626304, 1.84626304,\n",
       "        1.84626304, 1.84626304, 1.84626304, 1.84626304, 1.84626304,\n",
       "        1.84626304, 1.84626304, 1.84626304, 1.84626304, 1.84626304,\n",
       "        1.84626304, 1.84626304, 1.84626304, 1.84626304, 1.84626304,\n",
       "        1.84626304, 1.84626304, 1.84626304, 1.84626304, 1.84626304]),\n",
       " array([1.84626253, 1.84626221, 1.8462626 , 1.8462626 , 1.8462626 ,\n",
       "        1.8462626 , 1.8462626 , 1.84626254, 1.84626254, 1.84626254,\n",
       "        1.84626254, 1.84626254, 1.84626254, 1.8462625 , 1.84626247,\n",
       "        1.84626026, 1.84626247, 1.84626246, 1.84626248, 1.84626214,\n",
       "        1.84626214, 1.84626247, 1.84626247, 1.84626247, 1.84626211,\n",
       "        1.84626249, 1.84626249, 1.84626258, 1.84626249, 1.84626192,\n",
       "        1.84626211, 1.84626211, 1.84626253, 1.84626257, 1.84626249,\n",
       "        1.8462625 , 1.84626257, 1.84626249, 1.84626233, 1.84626258,\n",
       "        1.84626273, 1.84626273, 1.84626273, 1.84626273, 1.84626272,\n",
       "        1.84626273, 1.84626279, 1.84626279, 1.84626279, 1.84626279,\n",
       "        1.84626279, 1.84626279, 1.84626254, 1.8462625 , 1.84626026,\n",
       "        1.84626266, 1.84626266, 1.84626266, 1.84626214, 1.84626269,\n",
       "        1.84626272, 1.84626247, 1.84626272, 1.84626266, 1.84626211,\n",
       "        1.84626267, 1.84626249, 1.84626277, 1.84626277, 1.84626266,\n",
       "        1.84626249, 1.84626192, 1.84626253, 1.84626266, 1.84626268,\n",
       "        1.84626249, 1.8462625 , 1.84626268, 1.84626276, 1.84626249,\n",
       "        1.84626292, 1.84626292, 1.84626293, 1.84626293, 1.84626291,\n",
       "        1.84626292, 1.84626298, 1.84626298, 1.84626298, 1.84626298,\n",
       "        1.84626298, 1.84626254, 1.84626298, 1.8462625 , 1.84626026,\n",
       "        1.84626285, 1.84626285, 1.84626269, 1.84626291, 1.84626291,\n",
       "        1.84626247, 1.84626286, 1.84626291, 1.84626211, 1.84626249,\n",
       "        1.84626296, 1.84626296, 1.84626287, 1.84626266, 1.84626296,\n",
       "        1.84626253, 1.84626285, 1.84626288, 1.84626287, 1.8462625 ,\n",
       "        1.84626276, 1.84626285, 1.84626249, 1.84626287, 1.84626296]),\n",
       " array([-2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -2.01100000e-07, -2.01100000e-07, -2.01100000e-07, -2.01100000e-07,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "        -7.40000017e-09, -7.40000017e-09, -7.40000017e-09, -7.40000017e-09,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07,\n",
       "         1.85600000e-07,  1.85600000e-07,  1.85600000e-07,  1.85600000e-07]),\n",
       " array([-3.24300000e-07, -6.39400000e-07, -2.56100000e-07, -2.56000000e-07,\n",
       "        -2.56000000e-07, -2.55900000e-07, -2.55900000e-07, -3.10400000e-07,\n",
       "        -3.10400000e-07, -3.10300000e-07, -3.10200000e-07, -3.10300000e-07,\n",
       "        -3.10200000e-07, -3.53300000e-07, -3.84800000e-07, -2.59210000e-06,\n",
       "        -3.85500000e-07, -3.90000000e-07, -3.68100000e-07, -7.09000000e-07,\n",
       "        -7.08200000e-07, -3.85600000e-07, -3.78900000e-07, -3.80500000e-07,\n",
       "        -7.39800000e-07, -3.57800000e-07, -3.61400000e-07, -2.68400000e-07,\n",
       "        -3.61100000e-07, -9.35000000e-07, -7.46000000e-07, -7.45500000e-07,\n",
       "        -3.23700000e-07, -2.81700000e-07, -3.61000000e-07, -3.55200000e-07,\n",
       "        -2.83600000e-07, -3.61300000e-07, -5.21600000e-07, -2.72400000e-07,\n",
       "        -1.18900000e-07, -1.19200000e-07, -1.19100000e-07, -1.18800000e-07,\n",
       "        -1.31700000e-07, -1.19600000e-07, -6.35000001e-08, -6.38000002e-08,\n",
       "        -6.36000002e-08, -6.35000001e-08, -6.33000001e-08, -6.61000001e-08,\n",
       "        -3.10300000e-07, -3.53300000e-07, -2.59210000e-06, -1.94200000e-07,\n",
       "        -1.93700000e-07, -1.90000000e-07, -7.09000000e-07, -1.62700000e-07,\n",
       "        -1.30000000e-07, -3.78900000e-07, -1.34800000e-07, -1.93700000e-07,\n",
       "        -7.39800000e-07, -1.78700000e-07, -3.61400000e-07, -8.26000002e-08,\n",
       "        -8.14000001e-08, -1.94900000e-07, -3.61200000e-07, -9.35100000e-07,\n",
       "        -3.23800000e-07, -1.92000000e-07, -1.68500000e-07, -3.61100000e-07,\n",
       "        -3.55300000e-07, -1.69600000e-07, -8.71000001e-08, -3.61400000e-07,\n",
       "         7.34999999e-08,  7.36999999e-08,  7.38999999e-08,  7.38999999e-08,\n",
       "         6.26999999e-08,  7.35999999e-08,  1.29700000e-07,  1.29500000e-07,\n",
       "         1.29600000e-07,  1.29600000e-07,  1.29800000e-07, -3.10400000e-07,\n",
       "         1.28400000e-07, -3.53400000e-07, -2.59220000e-06, -2.00000017e-10,\n",
       "         2.99999803e-10, -1.62800000e-07,  6.31999999e-08,  5.95999998e-08,\n",
       "        -3.79000000e-07,  4.29999991e-09,  5.61000000e-08, -7.39900000e-07,\n",
       "        -3.61500000e-07,  1.10700000e-07,  1.13100000e-07,  1.90999998e-08,\n",
       "        -1.94900000e-07,  1.09800000e-07, -3.23800000e-07, -1.50000012e-09,\n",
       "         2.42999998e-08,  1.84000000e-08, -3.55300000e-07, -8.71000001e-08,\n",
       "        -1.10000009e-09, -3.61400000e-07,  2.18999998e-08,  1.07600000e-07]),\n",
       " array([  1.84626285,   1.        , 231.4029    , 158.41515   ]),\n",
       " array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False]),\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_db[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Optional, Any\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Module, MultiheadAttention, ModuleList, Dropout, Linear, Linear, LayerNorm\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "class TransformerEncoder(Module):\n",
    "    __constants__ = ['norm']\n",
    "\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = _get_clones(encoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src: Tensor, mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
    "        output = src\n",
    "\n",
    "        for mod in self.layers:\n",
    "            output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "#         if self.norm is not None:\n",
    "#             output = self.norm(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = Linear(d_model, dim_feedforward)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.linear2 = Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = F.relu\n",
    "        super(TransformerEncoderLayer, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
    "        src2 = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]\n",
    "        src = src + self.dropout1(src2)\n",
    "#         src = self.norm1(src)\n",
    "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = src + self.dropout2(src2)\n",
    "#         src = self.norm2(src)\n",
    "        return src\n",
    "    \n",
    "    \n",
    "def _get_clones(module, N):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "\n",
    "def _get_activation_fn(activation):\n",
    "    if activation == \"relu\":\n",
    "        return F.relu\n",
    "    elif activation == \"gelu\":\n",
    "        return F.gelu\n",
    "\n",
    "    raise RuntimeError(\"activation should be relu/gelu, not {}\".format(activation))\n",
    "    \n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_bssid = 128\n",
    "dim_rssi = 16\n",
    "dim_time = 1\n",
    "d_model = 128\n",
    "max_bssid = 239312 # df_100.bssid.max() + 1\n",
    "max_rssi = 110\n",
    "# max_b_id = 7020\n",
    "\n",
    "class Transformer(Module):\n",
    "    def __init__(self, d_model: int = d_model, nhead: int = 8, num_encoder_layers: int = 4,\n",
    "                 dim_feedforward: int = d_model*4, dropout: float = 0.0, activation: str = \"relu\"):\n",
    "        super(Transformer, self).__init__()\n",
    "                 \n",
    "        self.emb_bssid = nn.Embedding(max_bssid, dim_bssid)\n",
    "        self.emb_rssi = nn.Embedding(max_rssi, dim_rssi)\n",
    "        \n",
    "#         self.norm = nn.LayerNorm(dim_bssid+dim_rssi+dim_time*3)\n",
    "        self.v = nn.Linear(dim_bssid+dim_rssi+5, d_model)     \n",
    "        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, nn.LayerNorm(d_model))\n",
    "        self._reset_parameters()          \n",
    "\n",
    "        self.w = nn.Linear(d_model, CFG.n_tar * 3)  \n",
    "                 \n",
    "    def forward(self, bssid, rssi, resp, time, lst, d_time, d_lst, y, mask_b, mask_t):\n",
    "        bssid = self.emb_bssid(bssid).type(torch.float64)\n",
    "        rssi = self.emb_rssi(rssi).type(torch.float64)\n",
    "        resp, time, lst, d_time, d_lst = resp.unsqueeze(-1), time.unsqueeze(-1), lst.unsqueeze(-1), d_time.unsqueeze(-1), d_lst.unsqueeze(-1)\n",
    "        x = torch.cat([bssid, rssi, resp, time, lst, d_time, d_lst], dim=-1)\n",
    "        \n",
    "#         x = self.norm(x)\n",
    "        x = self.v(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.encoder(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = x[:, -1] \n",
    "\n",
    "        x = self.w(x)         \n",
    "        return x\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz: int) -> Tensor:\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask    \n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_batch = 4\n",
    "bssid = torch.zeros([size_batch, CFG.n_time*CFG.n_bssid], dtype=torch.int64)\n",
    "rssi = torch.zeros([size_batch, CFG.n_time*CFG.n_bssid], dtype=torch.int64)\n",
    "resp = torch.zeros([size_batch, CFG.n_time*CFG.n_bssid], dtype=torch.float64)\n",
    "time = torch.zeros([size_batch, CFG.n_time*CFG.n_bssid], dtype=torch.float64)\n",
    "lst = torch.zeros([size_batch, CFG.n_time*CFG.n_bssid], dtype=torch.float64)\n",
    "d_time = torch.zeros([size_batch, CFG.n_time*CFG.n_bssid], dtype=torch.float64)\n",
    "d_lst = torch.zeros([size_batch, CFG.n_time*CFG.n_bssid], dtype=torch.float64)\n",
    "y = torch.zeros([size_batch, 4])\n",
    "\n",
    "mask_b = torch.ones([size_batch, CFG.n_bssid]) == 0\n",
    "mask_t = torch.ones([size_batch, 1, CFG.n_time])\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "Transformer()(bssid, rssi, resp, time, lst, d_time, d_lst, y, mask_b, mask_t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_batch = 4\n",
    "# bssid = torch.zeros([size_batch, CFG.n_bssid], dtype=torch.int64)\n",
    "# rssi = torch.zeros([size_batch, CFG.n_bssid], dtype=torch.int64)\n",
    "# time = torch.zeros([size_batch])\n",
    "# y = torch.zeros([size_batch, 4])\n",
    "# mask_b = torch.ones([size_batch, 1, CFG.n_bssid])\n",
    "# mask_t = torch.ones([size_batch, 1])\n",
    "# tar_idx = torch.ones([size_batch], dtype=torch.int64)\n",
    "\n",
    "# Transformer()(bssid, rssi, time, y, mask_b, mask_t, tar_idx).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def unitwise_norm(x, norm_type=2.0):\n",
    "    if x.ndim <= 1:\n",
    "        return x.norm(norm_type)\n",
    "    else:\n",
    "        # works for nn.ConvNd and nn.Linear where output dim is first in the kernel/weight tensor\n",
    "        # might need special cases for other weights (possibly MHA) where this may not be true\n",
    "#         return x.norm(norm_type, dim=tuple(range(1, x.ndim)), keepdim=True)\n",
    "        return x.norm(norm_type, dim=tuple(range(0, x.ndim)), keepdim=True)\n",
    "\n",
    "\n",
    "def adaptive_clip_grad(parameters, clip_factor=0.01, eps=1e-3, norm_type=2.0):\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    for p in parameters:\n",
    "        if p.grad is None:\n",
    "            continue\n",
    "        p_data = p.detach()\n",
    "        g_data = p.grad.detach()\n",
    "        max_norm = unitwise_norm(p_data, norm_type=norm_type).clamp_(min=eps).mul_(clip_factor)\n",
    "        grad_norm = unitwise_norm(g_data, norm_type=norm_type)\n",
    "        clipped_grad = g_data * (max_norm / grad_norm.clamp(min=1e-6))\n",
    "        new_grads = torch.where(grad_norm < max_norm, g_data, clipped_grad)\n",
    "        p.grad.detach().copy_(new_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iln_loss(pred, y):\n",
    "    return torch.mean(torch.abs(pred[:, 0] - y[:, 1]) * 15 + ((pred[:, 1] - y[:, 2]) ** 2 + (pred[:, 2] - y[:, 3]) ** 2) ** 0.5)\n",
    "\n",
    "def iln_loss_valid(pred, y_int, y_t):\n",
    "    pred, y_int, y_t = pred.detach().cpu().numpy(), y_int.detach().cpu().numpy(), y_t.detach().cpu().numpy()\n",
    "    ar = np.zeros((len(y_t), 3))\n",
    "    for i in range(len(y_t)):\n",
    "        ar[i, 0] = np.interp(y_t[i, 0], y_int[i, :, 0], pred[i, :, 0])\n",
    "        ar[i, 1] = np.interp(y_t[i, 0], y_int[i, :, 0], pred[i, :, 1])\n",
    "        ar[i, 2] = np.interp(y_t[i, 0], y_int[i, :, 0], pred[i, :, 2])\n",
    "        \n",
    "    return np.mean(np.abs(ar[:, 0] - y_t[:, 1]) * 15 + ((ar[:, 1] - y_t[:, 2]) ** 2 + (ar[:, 2] - y_t[:, 3]) ** 2) ** 0.5)\n",
    "\n",
    "# def iln_loss(pred, y):\n",
    "#     return torch.mean(torch.abs(pred[:, 0] - y[:, 1]) * 15 + ((pred[:, 1] - y[:, 2]) ** 2 + (pred[:, 2] - y[:, 3]) ** 2) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(dataloaders, model, is_train):\n",
    "    start = time.time()\n",
    "    l_train_loss, l_valid_loss, l_tar, l_pred = [], [], [], []\n",
    "    \n",
    "    for i, (bssid, rssi, resp, t, lst, d_t, d_lst, y, mask_b, mask_t) in enumerate(dataloaders):\n",
    "        bssid, rssi, resp, t, lst, d_t, d_lst, y, mask_b, mask_t \\\n",
    "        = bssid.cuda(), rssi.cuda(), resp.cuda(), t.cuda(), lst.cuda(), d_t.cuda(), d_lst.cuda(), y.cuda(), mask_b.cuda(), mask_t.cuda()\n",
    "        \n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            pred = model(bssid, rssi, resp, t, lst, d_t, d_lst, y, mask_b, mask_t)\n",
    "            loss = iln_loss(pred, y)\n",
    "            l_train_loss.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "            if is_train:\n",
    "                loss.backward()\n",
    "                adaptive_clip_grad(model.parameters())\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "                if i % 1000 == 0:\n",
    "                    print('Step: %d Loss: %.4f Time: %.0f' %(i, np.array(l_train_loss).mean(), time.time()-start))\n",
    "                    start = time.time()                \n",
    "            else:\n",
    "                loss = iln_loss(pred, y)\n",
    "                l_valid_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    train_loss = np.array(l_train_loss).mean()\n",
    "    \n",
    "    if is_train:\n",
    "        return train_loss\n",
    "    else:\n",
    "        valid_loss = np.array(l_valid_loss).mean()\n",
    "        return train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "hist_loss_train, hist_loss_valid = {}, {}\n",
    "\n",
    "def run():\n",
    "    best_loss, best_epoch = 100, 0\n",
    "    for epoch in range(1000):\n",
    "        t = time.time()\n",
    "        _ = model.train()\n",
    "        train_loss = run_epoch(train_loader, model, True)\n",
    "        hist_loss_train[epoch] = train_loss\n",
    "        print('Epoch: %d Loss: %.4f Time: %0.f' %(epoch, train_loss, time.time()-t))\n",
    "        \n",
    "        t = time.time()\n",
    "        _ = model.eval()        \n",
    "        train_loss, valid_loss = run_epoch(valid_loader, model, False)\n",
    "        hist_loss_valid[epoch] = valid_loss\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "#             torch.save(model.state_dict(), checkpoint_path)\n",
    "            best_epoch = epoch\n",
    "            best_loss = valid_loss\n",
    "        print('Epoch: %d V_Loss: %.4f Best: %.4f %d' %(epoch, valid_loss, best_loss, best_epoch))\n",
    "#         print('Epoch: %d V_Loss: %.4f Best: %.4f %d lr: %.6f' %(epoch, valid_loss, best_loss, best_epoch, scheduler.get_last_lr()[0]))\n",
    "        print('')        \n",
    "        \n",
    "#         scheduler.step(valid_loss)\n",
    "#         scheduler.step()\n",
    "        \n",
    "    return best_epoch, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (emb_bssid): Embedding(239312, 128)\n",
       "  (emb_rssi): Embedding(110, 16)\n",
       "  (v): Linear(in_features=149, out_features=128, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (w): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=0.0003) \n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min')\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=20, gamma=0.9)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Loss: 240.3790 Time: 0\n",
      "Step: 1000 Loss: 69.6358 Time: 57\n",
      "Step: 2000 Loss: 46.0408 Time: 57\n",
      "Step: 3000 Loss: 36.8063 Time: 57\n",
      "Epoch: 0 Loss: 33.3404 Time: 206\n",
      "Epoch: 0 V_Loss: 17.5565 Best: 17.5565 0\n",
      "\n",
      "Step: 0 Loss: 15.6951 Time: 0\n",
      "Step: 1000 Loss: 14.6484 Time: 59\n",
      "Step: 2000 Loss: 14.2271 Time: 57\n",
      "Step: 3000 Loss: 13.7628 Time: 57\n",
      "Epoch: 1 Loss: 13.5358 Time: 207\n",
      "Epoch: 1 V_Loss: 12.7876 Best: 12.7876 1\n",
      "\n",
      "Step: 0 Loss: 10.0931 Time: 0\n",
      "Step: 1000 Loss: 11.6924 Time: 57\n",
      "Step: 2000 Loss: 11.4768 Time: 56\n",
      "Step: 3000 Loss: 11.2393 Time: 56\n",
      "Epoch: 2 Loss: 11.1076 Time: 205\n",
      "Epoch: 2 V_Loss: 11.9062 Best: 11.9062 2\n",
      "\n",
      "Step: 0 Loss: 8.7948 Time: 0\n",
      "Step: 1000 Loss: 9.9703 Time: 56\n",
      "Step: 2000 Loss: 9.8885 Time: 57\n",
      "Step: 3000 Loss: 9.8836 Time: 56\n",
      "Epoch: 3 Loss: 9.8156 Time: 205\n",
      "Epoch: 3 V_Loss: 12.4399 Best: 11.9062 2\n",
      "\n",
      "Step: 0 Loss: 9.4910 Time: 0\n",
      "Step: 1000 Loss: 9.2546 Time: 56\n",
      "Step: 2000 Loss: 9.1136 Time: 56\n",
      "Step: 3000 Loss: 9.0479 Time: 58\n",
      "Epoch: 4 Loss: 9.0055 Time: 206\n",
      "Epoch: 4 V_Loss: 11.5565 Best: 11.5565 4\n",
      "\n",
      "Step: 0 Loss: 9.0046 Time: 0\n",
      "Step: 1000 Loss: 8.5169 Time: 57\n",
      "Step: 2000 Loss: 8.5046 Time: 57\n",
      "Step: 3000 Loss: 8.4382 Time: 57\n",
      "Epoch: 5 Loss: 8.4289 Time: 207\n",
      "Epoch: 5 V_Loss: 11.5525 Best: 11.5525 5\n",
      "\n",
      "Step: 0 Loss: 8.2845 Time: 0\n",
      "Step: 1000 Loss: 8.0986 Time: 58\n",
      "Step: 2000 Loss: 8.0538 Time: 58\n",
      "Step: 3000 Loss: 8.0043 Time: 57\n",
      "Epoch: 6 Loss: 7.9977 Time: 208\n",
      "Epoch: 6 V_Loss: 11.1540 Best: 11.1540 6\n",
      "\n",
      "Step: 0 Loss: 8.6040 Time: 0\n",
      "Step: 1000 Loss: 7.6809 Time: 58\n",
      "Step: 2000 Loss: 7.6945 Time: 57\n",
      "Step: 3000 Loss: 7.7198 Time: 58\n",
      "Epoch: 7 Loss: 7.7020 Time: 208\n",
      "Epoch: 7 V_Loss: 11.0942 Best: 11.0942 7\n",
      "\n",
      "Step: 0 Loss: 7.4487 Time: 0\n",
      "Step: 1000 Loss: 7.3962 Time: 56\n",
      "Step: 2000 Loss: 7.3326 Time: 56\n",
      "Step: 3000 Loss: 7.2929 Time: 57\n",
      "Epoch: 8 Loss: 7.2616 Time: 205\n",
      "Epoch: 8 V_Loss: 10.5314 Best: 10.5314 8\n",
      "\n",
      "Step: 0 Loss: 6.9955 Time: 0\n",
      "Step: 1000 Loss: 6.9932 Time: 57\n",
      "Step: 2000 Loss: 6.9770 Time: 57\n",
      "Step: 3000 Loss: 6.9651 Time: 57\n",
      "Epoch: 9 Loss: 6.9392 Time: 207\n",
      "Epoch: 9 V_Loss: 9.5892 Best: 9.5892 9\n",
      "\n",
      "Step: 0 Loss: 5.4388 Time: 0\n",
      "Step: 1000 Loss: 6.6851 Time: 57\n",
      "Step: 2000 Loss: 6.6298 Time: 57\n",
      "Step: 3000 Loss: 6.6465 Time: 58\n",
      "Epoch: 10 Loss: 6.6308 Time: 208\n",
      "Epoch: 10 V_Loss: 9.7651 Best: 9.5892 9\n",
      "\n",
      "Step: 0 Loss: 6.4205 Time: 0\n",
      "Step: 1000 Loss: 6.4521 Time: 59\n",
      "Step: 2000 Loss: 6.4470 Time: 57\n",
      "Step: 3000 Loss: 6.4221 Time: 57\n",
      "Epoch: 11 Loss: 6.4118 Time: 208\n",
      "Epoch: 11 V_Loss: 9.0335 Best: 9.0335 11\n",
      "\n",
      "Step: 0 Loss: 5.4650 Time: 0\n",
      "Step: 1000 Loss: 6.2588 Time: 57\n",
      "Step: 2000 Loss: 6.2531 Time: 56\n",
      "Step: 3000 Loss: 6.2940 Time: 57\n",
      "Epoch: 12 Loss: 6.2961 Time: 206\n",
      "Epoch: 12 V_Loss: 9.4589 Best: 9.0335 11\n",
      "\n",
      "Step: 0 Loss: 5.9697 Time: 0\n",
      "Step: 1000 Loss: 6.2056 Time: 56\n",
      "Step: 2000 Loss: 6.1885 Time: 57\n",
      "Step: 3000 Loss: 6.1601 Time: 56\n",
      "Epoch: 13 Loss: 6.1430 Time: 205\n",
      "Epoch: 13 V_Loss: 9.6887 Best: 9.0335 11\n",
      "\n",
      "Step: 0 Loss: 6.0838 Time: 0\n",
      "Step: 1000 Loss: 6.0167 Time: 57\n",
      "Step: 2000 Loss: 6.0194 Time: 57\n",
      "Step: 3000 Loss: 5.9934 Time: 56\n",
      "Epoch: 14 Loss: 5.9821 Time: 205\n",
      "Epoch: 14 V_Loss: 8.8894 Best: 8.8894 14\n",
      "\n",
      "Step: 0 Loss: 5.3000 Time: 0\n",
      "Step: 1000 Loss: 5.8326 Time: 57\n",
      "Step: 2000 Loss: 5.8449 Time: 57\n",
      "Step: 3000 Loss: 5.8163 Time: 57\n",
      "Epoch: 15 Loss: 5.8048 Time: 206\n",
      "Epoch: 15 V_Loss: 9.2542 Best: 8.8894 14\n",
      "\n",
      "Step: 0 Loss: 5.9286 Time: 0\n",
      "Step: 1000 Loss: 5.6778 Time: 57\n",
      "Step: 2000 Loss: 5.6671 Time: 57\n",
      "Step: 3000 Loss: 5.6486 Time: 57\n",
      "Epoch: 16 Loss: 5.6528 Time: 206\n",
      "Epoch: 16 V_Loss: 9.4283 Best: 8.8894 14\n",
      "\n",
      "Step: 0 Loss: 6.2929 Time: 0\n",
      "Step: 1000 Loss: 5.5492 Time: 57\n",
      "Step: 2000 Loss: 5.5585 Time: 58\n",
      "Step: 3000 Loss: 5.5462 Time: 63\n",
      "Epoch: 17 Loss: 5.5403 Time: 216\n",
      "Epoch: 17 V_Loss: 8.6816 Best: 8.6816 17\n",
      "\n",
      "Step: 0 Loss: 5.1590 Time: 0\n",
      "Step: 1000 Loss: 5.3948 Time: 62\n",
      "Step: 2000 Loss: 5.4058 Time: 62\n",
      "Step: 3000 Loss: 5.4043 Time: 61\n",
      "Epoch: 18 Loss: 5.4021 Time: 223\n",
      "Epoch: 18 V_Loss: 9.5303 Best: 8.6816 17\n",
      "\n",
      "Step: 0 Loss: 5.4976 Time: 0\n",
      "Step: 1000 Loss: 5.2999 Time: 62\n",
      "Step: 2000 Loss: 5.3052 Time: 62\n",
      "Step: 3000 Loss: 5.3067 Time: 62\n",
      "Epoch: 19 Loss: 5.2957 Time: 224\n",
      "Epoch: 19 V_Loss: 8.9203 Best: 8.6816 17\n",
      "\n",
      "Step: 0 Loss: 4.7816 Time: 0\n",
      "Step: 1000 Loss: 5.1952 Time: 62\n",
      "Step: 2000 Loss: 5.1921 Time: 62\n",
      "Step: 3000 Loss: 5.1950 Time: 62\n",
      "Epoch: 20 Loss: 5.1925 Time: 224\n",
      "Epoch: 20 V_Loss: 8.8110 Best: 8.6816 17\n",
      "\n",
      "Step: 0 Loss: 4.4911 Time: 0\n",
      "Step: 1000 Loss: 5.1235 Time: 62\n",
      "Step: 2000 Loss: 5.1833 Time: 62\n",
      "Step: 3000 Loss: 5.1814 Time: 62\n",
      "Epoch: 21 Loss: 5.1762 Time: 224\n",
      "Epoch: 21 V_Loss: 8.9858 Best: 8.6816 17\n",
      "\n",
      "Step: 0 Loss: 4.9831 Time: 0\n",
      "Step: 1000 Loss: 5.0770 Time: 63\n",
      "Step: 2000 Loss: 5.0966 Time: 63\n",
      "Step: 3000 Loss: 5.1005 Time: 62\n",
      "Epoch: 22 Loss: 5.1053 Time: 227\n",
      "Epoch: 22 V_Loss: 8.9321 Best: 8.6816 17\n",
      "\n",
      "Step: 0 Loss: 5.1346 Time: 0\n",
      "Step: 1000 Loss: 4.9627 Time: 59\n",
      "Step: 2000 Loss: 4.9716 Time: 59\n",
      "Step: 3000 Loss: 4.9688 Time: 59\n",
      "Epoch: 23 Loss: 4.9705 Time: 213\n",
      "Epoch: 23 V_Loss: 8.2425 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 3.8790 Time: 0\n",
      "Step: 1000 Loss: 4.9548 Time: 59\n",
      "Step: 2000 Loss: 4.9325 Time: 60\n",
      "Step: 3000 Loss: 4.9305 Time: 61\n",
      "Epoch: 24 Loss: 4.9423 Time: 216\n",
      "Epoch: 24 V_Loss: 8.4338 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.9063 Time: 0\n",
      "Step: 1000 Loss: 4.8818 Time: 59\n",
      "Step: 2000 Loss: 4.8771 Time: 59\n",
      "Step: 3000 Loss: 4.8452 Time: 62\n",
      "Epoch: 25 Loss: 4.8388 Time: 219\n",
      "Epoch: 25 V_Loss: 8.8985 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 5.0617 Time: 0\n",
      "Step: 1000 Loss: 4.7447 Time: 62\n",
      "Step: 2000 Loss: 4.7650 Time: 60\n",
      "Step: 3000 Loss: 4.7767 Time: 59\n",
      "Epoch: 26 Loss: 4.7744 Time: 218\n",
      "Epoch: 26 V_Loss: 9.1318 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 5.4856 Time: 0\n",
      "Step: 1000 Loss: 4.7217 Time: 59\n",
      "Step: 2000 Loss: 4.7074 Time: 58\n",
      "Step: 3000 Loss: 4.7034 Time: 59\n",
      "Epoch: 27 Loss: 4.6992 Time: 212\n",
      "Epoch: 27 V_Loss: 8.5252 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.6747 Time: 0\n",
      "Step: 1000 Loss: 4.6125 Time: 59\n",
      "Step: 2000 Loss: 4.6213 Time: 62\n",
      "Step: 3000 Loss: 4.6279 Time: 60\n",
      "Epoch: 28 Loss: 4.6333 Time: 217\n",
      "Epoch: 28 V_Loss: 8.7133 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.5085 Time: 0\n",
      "Step: 1000 Loss: 4.5777 Time: 60\n",
      "Step: 2000 Loss: 4.5644 Time: 61\n",
      "Step: 3000 Loss: 4.5918 Time: 60\n",
      "Epoch: 29 Loss: 4.6016 Time: 218\n",
      "Epoch: 29 V_Loss: 8.5233 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.2904 Time: 0\n",
      "Step: 1000 Loss: 4.5754 Time: 59\n",
      "Step: 2000 Loss: 4.5457 Time: 59\n",
      "Step: 3000 Loss: 4.5443 Time: 59\n",
      "Epoch: 30 Loss: 4.5454 Time: 213\n",
      "Epoch: 30 V_Loss: 8.4041 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.2568 Time: 0\n",
      "Step: 1000 Loss: 4.4310 Time: 60\n",
      "Step: 2000 Loss: 4.4527 Time: 60\n",
      "Step: 3000 Loss: 4.4734 Time: 59\n",
      "Epoch: 31 Loss: 4.4742 Time: 216\n",
      "Epoch: 31 V_Loss: 8.5839 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.1052 Time: 0\n",
      "Step: 1000 Loss: 4.4356 Time: 61\n",
      "Step: 2000 Loss: 4.4404 Time: 61\n",
      "Step: 3000 Loss: 4.4379 Time: 61\n",
      "Epoch: 32 Loss: 4.4487 Time: 222\n",
      "Epoch: 32 V_Loss: 8.4165 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.3752 Time: 0\n",
      "Step: 1000 Loss: 4.3668 Time: 61\n",
      "Step: 2000 Loss: 4.3633 Time: 62\n",
      "Step: 3000 Loss: 4.3700 Time: 61\n",
      "Epoch: 33 Loss: 4.3710 Time: 222\n",
      "Epoch: 33 V_Loss: 8.6036 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.7864 Time: 0\n",
      "Step: 1000 Loss: 4.3165 Time: 61\n",
      "Step: 2000 Loss: 4.3389 Time: 61\n",
      "Step: 3000 Loss: 4.3603 Time: 60\n",
      "Epoch: 34 Loss: 4.3580 Time: 219\n",
      "Epoch: 34 V_Loss: 8.6049 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.8983 Time: 0\n",
      "Step: 1000 Loss: 4.2889 Time: 57\n",
      "Step: 2000 Loss: 4.3019 Time: 61\n",
      "Step: 3000 Loss: 4.3047 Time: 61\n",
      "Epoch: 35 Loss: 4.3128 Time: 218\n",
      "Epoch: 35 V_Loss: 8.4944 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.5027 Time: 0\n",
      "Step: 1000 Loss: 4.2650 Time: 60\n",
      "Step: 2000 Loss: 4.2737 Time: 59\n",
      "Step: 3000 Loss: 4.2801 Time: 61\n",
      "Epoch: 36 Loss: 4.2866 Time: 217\n",
      "Epoch: 36 V_Loss: 8.4561 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.2032 Time: 0\n",
      "Step: 1000 Loss: 4.2502 Time: 59\n",
      "Step: 2000 Loss: 4.2180 Time: 58\n",
      "Step: 3000 Loss: 4.2426 Time: 57\n",
      "Epoch: 37 Loss: 4.2426 Time: 211\n",
      "Epoch: 37 V_Loss: 8.4964 Best: 8.2425 23\n",
      "\n",
      "Step: 0 Loss: 4.5426 Time: 0\n",
      "Step: 1000 Loss: 4.2247 Time: 58\n",
      "Step: 2000 Loss: 4.2135 Time: 57\n",
      "Step: 3000 Loss: 4.2085 Time: 57\n",
      "Epoch: 38 Loss: 4.2279 Time: 208\n",
      "Epoch: 38 V_Loss: 7.9608 Best: 7.9608 38\n",
      "\n",
      "Step: 0 Loss: 3.9335 Time: 0\n",
      "Step: 1000 Loss: 4.1368 Time: 56\n",
      "Step: 2000 Loss: 4.1591 Time: 58\n",
      "Step: 3000 Loss: 4.1684 Time: 59\n",
      "Epoch: 39 Loss: 4.1728 Time: 211\n",
      "Epoch: 39 V_Loss: 8.1712 Best: 7.9608 38\n",
      "\n",
      "Step: 0 Loss: 4.2879 Time: 0\n",
      "Step: 1000 Loss: 4.1137 Time: 60\n",
      "Step: 2000 Loss: 4.1467 Time: 59\n",
      "Step: 3000 Loss: 4.1515 Time: 59\n",
      "Epoch: 40 Loss: 4.1422 Time: 214\n",
      "Epoch: 40 V_Loss: 8.0010 Best: 7.9608 38\n",
      "\n",
      "Step: 0 Loss: 3.7873 Time: 0\n",
      "Step: 1000 Loss: 4.0639 Time: 58\n",
      "Step: 2000 Loss: 4.0753 Time: 59\n",
      "Step: 3000 Loss: 4.0968 Time: 58\n",
      "Epoch: 41 Loss: 4.1084 Time: 212\n",
      "Epoch: 41 V_Loss: 8.3758 Best: 7.9608 38\n",
      "\n",
      "Step: 0 Loss: 3.7649 Time: 0\n",
      "Step: 1000 Loss: 4.0695 Time: 59\n",
      "Step: 2000 Loss: 4.0794 Time: 59\n",
      "Step: 3000 Loss: 4.0778 Time: 59\n",
      "Epoch: 42 Loss: 4.0801 Time: 214\n",
      "Epoch: 42 V_Loss: 8.0882 Best: 7.9608 38\n",
      "\n",
      "Step: 0 Loss: 3.5249 Time: 0\n",
      "Step: 1000 Loss: 4.0638 Time: 59\n",
      "Step: 2000 Loss: 4.0608 Time: 59\n",
      "Step: 3000 Loss: 4.0767 Time: 60\n",
      "Epoch: 43 Loss: 4.0799 Time: 216\n",
      "Epoch: 43 V_Loss: 7.9351 Best: 7.9351 43\n",
      "\n",
      "Step: 0 Loss: 3.8840 Time: 0\n",
      "Step: 1000 Loss: 4.0157 Time: 58\n",
      "Step: 2000 Loss: 4.0488 Time: 58\n",
      "Step: 3000 Loss: 4.0473 Time: 59\n",
      "Epoch: 44 Loss: 4.0532 Time: 213\n",
      "Epoch: 44 V_Loss: 8.0914 Best: 7.9351 43\n",
      "\n",
      "Step: 0 Loss: 3.6075 Time: 0\n",
      "Step: 1000 Loss: 3.9820 Time: 59\n",
      "Step: 2000 Loss: 3.9988 Time: 60\n",
      "Step: 3000 Loss: 4.0074 Time: 60\n",
      "Epoch: 45 Loss: 4.0130 Time: 218\n",
      "Epoch: 45 V_Loss: 8.0078 Best: 7.9351 43\n",
      "\n",
      "Step: 0 Loss: 3.3342 Time: 0\n",
      "Step: 1000 Loss: 3.9529 Time: 60\n",
      "Step: 2000 Loss: 3.9642 Time: 59\n",
      "Step: 3000 Loss: 3.9736 Time: 59\n",
      "Epoch: 46 Loss: 3.9769 Time: 215\n",
      "Epoch: 46 V_Loss: 8.1460 Best: 7.9351 43\n",
      "\n",
      "Step: 0 Loss: 3.8591 Time: 0\n",
      "Step: 1000 Loss: 3.9084 Time: 62\n",
      "Step: 2000 Loss: 3.9414 Time: 59\n",
      "Step: 3000 Loss: 3.9479 Time: 59\n",
      "Epoch: 47 Loss: 3.9477 Time: 219\n",
      "Epoch: 47 V_Loss: 8.0630 Best: 7.9351 43\n",
      "\n",
      "Step: 0 Loss: 3.6331 Time: 0\n",
      "Step: 1000 Loss: 3.9186 Time: 62\n",
      "Step: 2000 Loss: 3.9274 Time: 59\n",
      "Step: 3000 Loss: 3.9320 Time: 59\n",
      "Epoch: 48 Loss: 3.9361 Time: 217\n",
      "Epoch: 48 V_Loss: 7.9731 Best: 7.9351 43\n",
      "\n",
      "Step: 0 Loss: 3.9475 Time: 0\n",
      "Step: 1000 Loss: 3.8918 Time: 59\n",
      "Step: 2000 Loss: 3.8984 Time: 60\n",
      "Step: 3000 Loss: 3.9022 Time: 59\n",
      "Epoch: 49 Loss: 3.9059 Time: 215\n",
      "Epoch: 49 V_Loss: 8.0009 Best: 7.9351 43\n",
      "\n",
      "Step: 0 Loss: 4.0271 Time: 0\n",
      "Step: 1000 Loss: 3.9013 Time: 60\n",
      "Step: 2000 Loss: 3.9063 Time: 62\n",
      "Step: 3000 Loss: 3.9116 Time: 61\n",
      "Epoch: 50 Loss: 3.9179 Time: 219\n",
      "Epoch: 50 V_Loss: 8.0321 Best: 7.9351 43\n",
      "\n",
      "Step: 0 Loss: 3.5596 Time: 0\n",
      "Step: 1000 Loss: 3.8886 Time: 58\n",
      "Step: 2000 Loss: 3.9111 Time: 59\n",
      "Step: 3000 Loss: 3.9053 Time: 59\n",
      "Epoch: 51 Loss: 3.9054 Time: 212\n",
      "Epoch: 51 V_Loss: 7.8881 Best: 7.8881 51\n",
      "\n",
      "Step: 0 Loss: 3.5993 Time: 0\n",
      "Step: 1000 Loss: 3.8382 Time: 59\n",
      "Step: 2000 Loss: 3.8478 Time: 60\n",
      "Step: 3000 Loss: 3.8478 Time: 59\n",
      "Epoch: 52 Loss: 3.8391 Time: 215\n",
      "Epoch: 52 V_Loss: 8.0113 Best: 7.8881 51\n",
      "\n",
      "Step: 0 Loss: 3.4968 Time: 0\n",
      "Step: 1000 Loss: 3.7966 Time: 58\n",
      "Step: 2000 Loss: 3.8117 Time: 57\n",
      "Step: 3000 Loss: 3.8264 Time: 61\n",
      "Epoch: 53 Loss: 3.8258 Time: 214\n",
      "Epoch: 53 V_Loss: 8.1204 Best: 7.8881 51\n",
      "\n",
      "Step: 0 Loss: 3.4386 Time: 0\n",
      "Step: 1000 Loss: 3.8417 Time: 59\n",
      "Step: 2000 Loss: 3.8255 Time: 58\n",
      "Step: 3000 Loss: 3.8146 Time: 61\n",
      "Epoch: 54 Loss: 3.8208 Time: 219\n",
      "Epoch: 54 V_Loss: 7.9498 Best: 7.8881 51\n",
      "\n",
      "Step: 0 Loss: 4.0824 Time: 0\n",
      "Step: 1000 Loss: 3.7417 Time: 60\n",
      "Step: 2000 Loss: 3.7690 Time: 60\n",
      "Step: 3000 Loss: 3.7845 Time: 59\n",
      "Epoch: 55 Loss: 3.7953 Time: 215\n",
      "Epoch: 55 V_Loss: 8.4853 Best: 7.8881 51\n",
      "\n",
      "Step: 0 Loss: 3.9718 Time: 0\n",
      "Step: 1000 Loss: 3.7531 Time: 57\n",
      "Step: 2000 Loss: 3.7509 Time: 55\n",
      "Step: 3000 Loss: 3.7535 Time: 59\n",
      "Epoch: 56 Loss: 3.7551 Time: 209\n",
      "Epoch: 56 V_Loss: 8.2905 Best: 7.8881 51\n",
      "\n",
      "Step: 0 Loss: 3.8082 Time: 0\n",
      "Step: 1000 Loss: 3.6932 Time: 59\n",
      "Step: 2000 Loss: 3.7284 Time: 62\n",
      "Step: 3000 Loss: 3.7581 Time: 59\n",
      "Epoch: 57 Loss: 3.7699 Time: 216\n",
      "Epoch: 57 V_Loss: 7.9120 Best: 7.8881 51\n",
      "\n",
      "Step: 0 Loss: 4.2362 Time: 0\n",
      "Step: 1000 Loss: 3.7248 Time: 60\n",
      "Step: 2000 Loss: 3.7325 Time: 59\n",
      "Step: 3000 Loss: 3.7464 Time: 60\n",
      "Epoch: 58 Loss: 3.7447 Time: 216\n",
      "Epoch: 58 V_Loss: 7.8320 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.6776 Time: 0\n",
      "Step: 1000 Loss: 3.6940 Time: 59\n",
      "Step: 2000 Loss: 3.7332 Time: 59\n",
      "Step: 3000 Loss: 3.7456 Time: 56\n",
      "Epoch: 59 Loss: 3.7481 Time: 209\n",
      "Epoch: 59 V_Loss: 7.8955 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.6340 Time: 0\n",
      "Step: 1000 Loss: 3.6820 Time: 58\n",
      "Step: 2000 Loss: 3.7271 Time: 58\n",
      "Step: 3000 Loss: 3.7375 Time: 58\n",
      "Epoch: 60 Loss: 3.7380 Time: 210\n",
      "Epoch: 60 V_Loss: 8.2756 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.4476 Time: 0\n",
      "Step: 1000 Loss: 3.6896 Time: 57\n",
      "Step: 2000 Loss: 3.7176 Time: 57\n",
      "Step: 3000 Loss: 3.7228 Time: 57\n",
      "Epoch: 61 Loss: 3.7216 Time: 207\n",
      "Epoch: 61 V_Loss: 8.1204 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.3999 Time: 0\n",
      "Step: 1000 Loss: 3.6364 Time: 57\n",
      "Step: 2000 Loss: 3.6629 Time: 57\n",
      "Step: 3000 Loss: 3.6800 Time: 57\n",
      "Epoch: 62 Loss: 3.6813 Time: 208\n",
      "Epoch: 62 V_Loss: 8.3101 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.5215 Time: 0\n",
      "Step: 1000 Loss: 3.6451 Time: 56\n",
      "Step: 2000 Loss: 3.6507 Time: 56\n",
      "Step: 3000 Loss: 3.6578 Time: 55\n",
      "Epoch: 63 Loss: 3.6656 Time: 202\n",
      "Epoch: 63 V_Loss: 8.0660 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 4.0193 Time: 0\n",
      "Step: 1000 Loss: 3.5970 Time: 57\n",
      "Step: 2000 Loss: 3.6265 Time: 57\n",
      "Step: 3000 Loss: 3.6472 Time: 59\n",
      "Epoch: 64 Loss: 3.6653 Time: 211\n",
      "Epoch: 64 V_Loss: 8.1221 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.7807 Time: 0\n",
      "Step: 1000 Loss: 3.6553 Time: 56\n",
      "Step: 2000 Loss: 3.6433 Time: 56\n",
      "Step: 3000 Loss: 3.6374 Time: 57\n",
      "Epoch: 65 Loss: 3.6527 Time: 206\n",
      "Epoch: 65 V_Loss: 7.9745 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.6431 Time: 0\n",
      "Step: 1000 Loss: 3.5895 Time: 56\n",
      "Step: 2000 Loss: 3.6135 Time: 56\n",
      "Step: 3000 Loss: 3.6333 Time: 56\n",
      "Epoch: 66 Loss: 3.6403 Time: 204\n",
      "Epoch: 66 V_Loss: 8.0503 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 4.1208 Time: 0\n",
      "Step: 1000 Loss: 3.6243 Time: 57\n",
      "Step: 2000 Loss: 3.6054 Time: 57\n",
      "Step: 3000 Loss: 3.6344 Time: 57\n",
      "Epoch: 67 Loss: 3.6365 Time: 206\n",
      "Epoch: 67 V_Loss: 8.0158 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.5044 Time: 0\n",
      "Step: 1000 Loss: 3.5965 Time: 57\n",
      "Step: 2000 Loss: 3.5887 Time: 57\n",
      "Step: 3000 Loss: 3.5901 Time: 57\n",
      "Epoch: 68 Loss: 3.5921 Time: 207\n",
      "Epoch: 68 V_Loss: 7.9145 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 4.1566 Time: 0\n",
      "Step: 1000 Loss: 3.5293 Time: 59\n",
      "Step: 2000 Loss: 3.5350 Time: 58\n",
      "Step: 3000 Loss: 3.5460 Time: 58\n",
      "Epoch: 69 Loss: 3.5575 Time: 211\n",
      "Epoch: 69 V_Loss: 7.8731 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.1532 Time: 0\n",
      "Step: 1000 Loss: 3.5250 Time: 57\n",
      "Step: 2000 Loss: 3.5715 Time: 57\n",
      "Step: 3000 Loss: 3.5988 Time: 57\n",
      "Epoch: 70 Loss: 3.6005 Time: 206\n",
      "Epoch: 70 V_Loss: 7.9626 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.6381 Time: 0\n",
      "Step: 1000 Loss: 3.5345 Time: 59\n",
      "Step: 2000 Loss: 3.5639 Time: 58\n",
      "Step: 3000 Loss: 3.5638 Time: 57\n",
      "Epoch: 71 Loss: 3.5604 Time: 209\n",
      "Epoch: 71 V_Loss: 7.8650 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.9254 Time: 0\n",
      "Step: 1000 Loss: 3.5082 Time: 57\n",
      "Step: 2000 Loss: 3.5215 Time: 57\n",
      "Step: 3000 Loss: 3.5175 Time: 57\n",
      "Epoch: 72 Loss: 3.5227 Time: 205\n",
      "Epoch: 72 V_Loss: 7.8639 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.0938 Time: 0\n",
      "Step: 1000 Loss: 3.5074 Time: 57\n",
      "Step: 2000 Loss: 3.5238 Time: 61\n",
      "Step: 3000 Loss: 3.5270 Time: 58\n",
      "Epoch: 73 Loss: 3.5296 Time: 211\n",
      "Epoch: 73 V_Loss: 7.8554 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.6569 Time: 0\n",
      "Step: 1000 Loss: 3.4769 Time: 57\n",
      "Step: 2000 Loss: 3.4769 Time: 59\n",
      "Step: 3000 Loss: 3.4831 Time: 60\n",
      "Epoch: 74 Loss: 3.4949 Time: 212\n",
      "Epoch: 74 V_Loss: 7.9692 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.4450 Time: 0\n",
      "Step: 1000 Loss: 3.4734 Time: 58\n",
      "Step: 2000 Loss: 3.4738 Time: 58\n",
      "Step: 3000 Loss: 3.4791 Time: 58\n",
      "Epoch: 75 Loss: 3.4885 Time: 211\n",
      "Epoch: 75 V_Loss: 7.8667 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.2615 Time: 0\n",
      "Step: 1000 Loss: 3.4715 Time: 60\n",
      "Step: 2000 Loss: 3.4965 Time: 58\n",
      "Step: 3000 Loss: 3.4989 Time: 59\n",
      "Epoch: 76 Loss: 3.5079 Time: 215\n",
      "Epoch: 76 V_Loss: 8.3044 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.2438 Time: 0\n",
      "Step: 1000 Loss: 3.5012 Time: 59\n",
      "Step: 2000 Loss: 3.4944 Time: 59\n",
      "Step: 3000 Loss: 3.4909 Time: 60\n",
      "Epoch: 77 Loss: 3.4887 Time: 214\n",
      "Epoch: 77 V_Loss: 8.1249 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.4179 Time: 0\n",
      "Step: 1000 Loss: 3.4534 Time: 59\n",
      "Step: 2000 Loss: 3.4712 Time: 59\n",
      "Step: 3000 Loss: 3.4707 Time: 60\n",
      "Epoch: 78 Loss: 3.4754 Time: 215\n",
      "Epoch: 78 V_Loss: 8.4480 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.4864 Time: 0\n",
      "Step: 1000 Loss: 3.4304 Time: 58\n",
      "Step: 2000 Loss: 3.4414 Time: 58\n",
      "Step: 3000 Loss: 3.4511 Time: 59\n",
      "Epoch: 79 Loss: 3.4484 Time: 212\n",
      "Epoch: 79 V_Loss: 7.9120 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.0768 Time: 0\n",
      "Step: 1000 Loss: 3.3811 Time: 59\n",
      "Step: 2000 Loss: 3.4012 Time: 59\n",
      "Step: 3000 Loss: 3.4137 Time: 58\n",
      "Epoch: 80 Loss: 3.4232 Time: 213\n",
      "Epoch: 80 V_Loss: 7.9609 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.5385 Time: 0\n",
      "Step: 1000 Loss: 3.4079 Time: 59\n",
      "Step: 2000 Loss: 3.4108 Time: 58\n",
      "Step: 3000 Loss: 3.4130 Time: 55\n",
      "Epoch: 81 Loss: 3.4144 Time: 206\n",
      "Epoch: 81 V_Loss: 7.9817 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.1925 Time: 0\n",
      "Step: 1000 Loss: 3.4112 Time: 56\n",
      "Step: 2000 Loss: 3.3940 Time: 55\n",
      "Step: 3000 Loss: 3.4208 Time: 55\n",
      "Epoch: 82 Loss: 3.4347 Time: 201\n",
      "Epoch: 82 V_Loss: 7.9032 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.1284 Time: 0\n",
      "Step: 1000 Loss: 3.4087 Time: 55\n",
      "Step: 2000 Loss: 3.3886 Time: 55\n",
      "Step: 3000 Loss: 3.4095 Time: 55\n",
      "Epoch: 83 Loss: 3.4152 Time: 199\n",
      "Epoch: 83 V_Loss: 7.9398 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.5133 Time: 0\n",
      "Step: 1000 Loss: 3.4169 Time: 55\n",
      "Step: 2000 Loss: 3.4129 Time: 56\n",
      "Step: 3000 Loss: 3.4163 Time: 55\n",
      "Epoch: 84 Loss: 3.4207 Time: 201\n",
      "Epoch: 84 V_Loss: 8.3453 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.1188 Time: 0\n",
      "Step: 1000 Loss: 3.4124 Time: 55\n",
      "Step: 2000 Loss: 3.3940 Time: 55\n",
      "Step: 3000 Loss: 3.4247 Time: 55\n",
      "Epoch: 85 Loss: 3.4241 Time: 199\n",
      "Epoch: 85 V_Loss: 8.3307 Best: 7.8320 58\n",
      "\n",
      "Step: 0 Loss: 3.6445 Time: 0\n",
      "Step: 1000 Loss: 3.3415 Time: 56\n",
      "Step: 2000 Loss: 3.3712 Time: 56\n",
      "Step: 3000 Loss: 3.3828 Time: 56\n",
      "Epoch: 86 Loss: 3.3869 Time: 202\n",
      "Epoch: 86 V_Loss: 7.6982 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.3016 Time: 0\n",
      "Step: 1000 Loss: 3.3927 Time: 55\n",
      "Step: 2000 Loss: 3.3759 Time: 55\n",
      "Step: 3000 Loss: 3.3814 Time: 57\n",
      "Epoch: 87 Loss: 3.3862 Time: 201\n",
      "Epoch: 87 V_Loss: 8.2103 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 4.0564 Time: 0\n",
      "Step: 1000 Loss: 3.3484 Time: 55\n",
      "Step: 2000 Loss: 3.3763 Time: 55\n",
      "Step: 3000 Loss: 3.3857 Time: 55\n",
      "Epoch: 88 Loss: 3.3849 Time: 200\n",
      "Epoch: 88 V_Loss: 8.4163 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.3095 Time: 0\n",
      "Step: 1000 Loss: 3.3461 Time: 55\n",
      "Step: 2000 Loss: 3.3602 Time: 56\n",
      "Step: 3000 Loss: 3.3666 Time: 56\n",
      "Epoch: 89 Loss: 3.3608 Time: 202\n",
      "Epoch: 89 V_Loss: 7.9651 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.7959 Time: 0\n",
      "Step: 1000 Loss: 3.3218 Time: 55\n",
      "Step: 2000 Loss: 3.3300 Time: 55\n",
      "Step: 3000 Loss: 3.3410 Time: 56\n",
      "Epoch: 90 Loss: 3.3452 Time: 201\n",
      "Epoch: 90 V_Loss: 7.8137 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.1390 Time: 0\n",
      "Step: 1000 Loss: 3.3053 Time: 57\n",
      "Step: 2000 Loss: 3.3290 Time: 56\n",
      "Step: 3000 Loss: 3.3304 Time: 55\n",
      "Epoch: 91 Loss: 3.3325 Time: 203\n",
      "Epoch: 91 V_Loss: 7.8805 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.0205 Time: 0\n",
      "Step: 1000 Loss: 3.2891 Time: 56\n",
      "Step: 2000 Loss: 3.2971 Time: 56\n",
      "Step: 3000 Loss: 3.3143 Time: 55\n",
      "Epoch: 92 Loss: 3.3221 Time: 202\n",
      "Epoch: 92 V_Loss: 7.9676 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.2297 Time: 0\n",
      "Step: 1000 Loss: 3.3118 Time: 55\n",
      "Step: 2000 Loss: 3.3026 Time: 55\n",
      "Step: 3000 Loss: 3.3085 Time: 55\n",
      "Step: 1000 Loss: 3.2772 Time: 56\n",
      "Step: 2000 Loss: 3.3005 Time: 55\n",
      "Step: 3000 Loss: 3.2996 Time: 55\n",
      "Epoch: 94 Loss: 3.3050 Time: 201\n",
      "Epoch: 94 V_Loss: 7.8381 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 2.6885 Time: 0\n",
      "Step: 1000 Loss: 3.3144 Time: 55\n",
      "Step: 2000 Loss: 3.3116 Time: 55\n",
      "Step: 3000 Loss: 3.3181 Time: 55\n",
      "Epoch: 95 Loss: 3.3244 Time: 201\n",
      "Epoch: 95 V_Loss: 7.9356 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.1745 Time: 0\n",
      "Step: 1000 Loss: 3.3310 Time: 55\n",
      "Step: 2000 Loss: 3.3103 Time: 56\n",
      "Step: 3000 Loss: 3.3186 Time: 55\n",
      "Epoch: 96 Loss: 3.3153 Time: 201\n",
      "Epoch: 96 V_Loss: 7.9543 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.1821 Time: 0\n",
      "Step: 1000 Loss: 3.2553 Time: 56\n",
      "Step: 2000 Loss: 3.2682 Time: 55\n",
      "Step: 3000 Loss: 3.2886 Time: 57\n",
      "Epoch: 97 Loss: 3.2920 Time: 203\n",
      "Epoch: 97 V_Loss: 7.8028 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.0030 Time: 0\n",
      "Step: 1000 Loss: 3.2459 Time: 56\n",
      "Step: 2000 Loss: 3.2768 Time: 55\n",
      "Step: 3000 Loss: 3.2850 Time: 57\n",
      "Epoch: 98 Loss: 3.2844 Time: 203\n",
      "Epoch: 98 V_Loss: 7.9023 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.0145 Time: 0\n",
      "Step: 1000 Loss: 3.2591 Time: 56\n",
      "Step: 2000 Loss: 3.2733 Time: 56\n",
      "Step: 3000 Loss: 3.2785 Time: 56\n",
      "Epoch: 99 Loss: 3.2794 Time: 202\n",
      "Epoch: 99 V_Loss: 8.0691 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.0372 Time: 0\n",
      "Step: 1000 Loss: 3.2226 Time: 55\n",
      "Step: 2000 Loss: 3.2798 Time: 56\n",
      "Step: 3000 Loss: 3.2787 Time: 56\n",
      "Epoch: 100 Loss: 3.2752 Time: 202\n",
      "Epoch: 100 V_Loss: 7.8712 Best: 7.6982 86\n",
      "\n",
      "Step: 0 Loss: 3.1253 Time: 0\n",
      "Step: 1000 Loss: 3.2581 Time: 56\n",
      "Step: 2000 Loss: 3.2619 Time: 56\n",
      "Step: 3000 Loss: 3.2784 Time: 55\n",
      "Epoch: 101 Loss: 3.2776 Time: 202\n",
      "Epoch: 101 V_Loss: 7.6806 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.5291 Time: 0\n",
      "Step: 1000 Loss: 3.3017 Time: 57\n",
      "Step: 2000 Loss: 3.2790 Time: 55\n",
      "Step: 3000 Loss: 3.2770 Time: 56\n",
      "Epoch: 102 Loss: 3.2819 Time: 202\n",
      "Epoch: 102 V_Loss: 7.9207 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.2163 Time: 0\n",
      "Step: 1000 Loss: 3.2092 Time: 56\n",
      "Step: 2000 Loss: 3.2519 Time: 55\n",
      "Step: 3000 Loss: 3.2571 Time: 55\n",
      "Epoch: 103 Loss: 3.2645 Time: 202\n",
      "Epoch: 103 V_Loss: 7.9661 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.4300 Time: 0\n",
      "Step: 1000 Loss: 3.2256 Time: 55\n",
      "Step: 2000 Loss: 3.2459 Time: 56\n",
      "Step: 3000 Loss: 3.2682 Time: 56\n",
      "Epoch: 104 Loss: 3.2713 Time: 201\n",
      "Epoch: 104 V_Loss: 8.3524 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.3639 Time: 0\n",
      "Step: 1000 Loss: 3.2551 Time: 55\n",
      "Step: 2000 Loss: 3.2793 Time: 55\n",
      "Step: 3000 Loss: 3.2907 Time: 55\n",
      "Epoch: 105 Loss: 3.2885 Time: 201\n",
      "Epoch: 105 V_Loss: 7.7188 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.1508 Time: 0\n",
      "Step: 1000 Loss: 3.2450 Time: 56\n",
      "Step: 2000 Loss: 3.2844 Time: 55\n",
      "Step: 3000 Loss: 3.2749 Time: 58\n",
      "Epoch: 106 Loss: 3.2883 Time: 204\n",
      "Epoch: 106 V_Loss: 7.8068 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.1095 Time: 0\n",
      "Step: 1000 Loss: 3.2059 Time: 55\n",
      "Step: 2000 Loss: 3.2220 Time: 55\n",
      "Step: 3000 Loss: 3.2464 Time: 55\n",
      "Epoch: 107 Loss: 3.2578 Time: 201\n",
      "Epoch: 107 V_Loss: 8.0919 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.1223 Time: 0\n",
      "Step: 1000 Loss: 3.1961 Time: 56\n",
      "Step: 2000 Loss: 3.2337 Time: 55\n",
      "Step: 3000 Loss: 3.2339 Time: 55\n",
      "Epoch: 108 Loss: 3.2495 Time: 201\n",
      "Epoch: 108 V_Loss: 7.8596 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.2139 Time: 0\n",
      "Step: 1000 Loss: 3.2691 Time: 56\n",
      "Step: 2000 Loss: 3.2701 Time: 56\n",
      "Step: 3000 Loss: 3.2596 Time: 57\n",
      "Epoch: 109 Loss: 3.2588 Time: 203\n",
      "Epoch: 109 V_Loss: 7.7721 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 2.9804 Time: 0\n",
      "Step: 1000 Loss: 3.2174 Time: 55\n",
      "Step: 2000 Loss: 3.2541 Time: 56\n",
      "Step: 3000 Loss: 3.2696 Time: 56\n",
      "Epoch: 110 Loss: 3.2729 Time: 201\n",
      "Epoch: 110 V_Loss: 7.8203 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.4053 Time: 0\n",
      "Step: 1000 Loss: 3.2237 Time: 56\n",
      "Step: 2000 Loss: 3.2271 Time: 56\n",
      "Step: 3000 Loss: 3.2564 Time: 55\n",
      "Epoch: 111 Loss: 3.2526 Time: 202\n",
      "Epoch: 111 V_Loss: 7.9675 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 2.8943 Time: 0\n",
      "Step: 1000 Loss: 3.2305 Time: 56\n",
      "Step: 2000 Loss: 3.2321 Time: 56\n",
      "Step: 3000 Loss: 3.2388 Time: 56\n",
      "Epoch: 112 Loss: 3.2465 Time: 202\n",
      "Epoch: 112 V_Loss: 8.4019 Best: 7.6806 101\n",
      "\n",
      "Step: 0 Loss: 3.5840 Time: 0\n",
      "Step: 1000 Loss: 3.2446 Time: 55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-a7981a8a300d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# float64 [b128, r16, resp, t, lst, d_t, d_lst]/[tr128/4]/w1 (3-1, 60-40-replace) v1 b64 do 0.0 mask_b x y_int StepLR(30-20-0.9) agc 0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-b84d8a71234e>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mhist_loss_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: %d Loss: %.4f Time: %0.f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-f22189d8d6a0>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(dataloaders, model, is_train)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ml_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_valid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbssid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrssi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mbssid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrssi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_t\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mbssid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrssi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# For wire compatibility with 3.2 and lower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m16384\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# The payload is large so Nagle's algorithm won't be triggered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run() # float64 [b128, r16, resp, t, lst, d_t, d_lst]/[tr128/4]/w1 (3-1, 60-40-replace) v1 b64 do 0.0 mask_b x y_int lr0.0003 agc 0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
